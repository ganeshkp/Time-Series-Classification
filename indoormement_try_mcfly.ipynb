{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('./MovementAAL/dataset/MovementAAL_RSS_1.csv')\n",
    "df2 = pd.read_csv('./MovementAAL/dataset/MovementAAL_RSS_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#RSS_anchor1</th>\n",
       "      <th>RSS_anchor2</th>\n",
       "      <th>RSS_anchor3</th>\n",
       "      <th>RSS_anchor4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.90476</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.28571</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.57143</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.14286</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.38095</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.14286</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.28571</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.47619</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.14286</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.14286</td>\n",
       "      <td>-0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #RSS_anchor1   RSS_anchor2   RSS_anchor3   RSS_anchor4\n",
       "0      -0.90476         -0.48       0.28571          0.30\n",
       "1      -0.57143         -0.32       0.14286          0.30\n",
       "2      -0.38095         -0.28      -0.14286          0.35\n",
       "3      -0.28571         -0.20      -0.47619          0.35\n",
       "4      -0.14286         -0.20       0.14286         -0.20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#RSS_anchor1</th>\n",
       "      <th>RSS_anchor2</th>\n",
       "      <th>RSS_anchor3</th>\n",
       "      <th>RSS_anchor4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.57143</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.71429</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.76190</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.76190</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.85714</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>0.85714</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.76190</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>0.71429</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.76190</td>\n",
       "      <td>-0.84</td>\n",
       "      <td>0.85714</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   #RSS_anchor1   RSS_anchor2   RSS_anchor3   RSS_anchor4\n",
       "0      -0.57143         -0.20       0.71429          0.50\n",
       "1      -0.76190         -0.48       0.76190         -0.25\n",
       "2      -0.85714         -0.60       0.85714          0.55\n",
       "3      -0.76190         -0.40       0.71429          0.60\n",
       "4      -0.76190         -0.84       0.85714          0.45"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./MovementAAL/dataset/MovementAAL_RSS_1.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_2.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_3.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_4.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_5.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_6.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_7.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_8.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_9.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_10.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_11.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_12.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_13.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_14.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_15.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_16.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_17.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_18.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_19.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_20.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_21.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_22.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_23.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_24.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_25.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_26.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_27.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_28.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_29.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_30.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_31.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_32.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_33.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_34.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_35.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_36.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_37.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_38.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_39.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_40.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_41.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_42.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_43.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_44.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_45.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_46.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_47.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_48.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_49.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_50.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_51.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_52.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_53.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_54.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_55.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_56.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_57.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_58.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_59.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_60.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_61.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_62.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_63.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_64.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_65.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_66.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_67.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_68.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_69.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_70.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_71.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_72.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_73.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_74.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_75.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_76.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_77.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_78.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_79.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_80.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_81.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_82.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_83.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_84.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_85.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_86.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_87.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_88.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_89.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_90.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_91.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_92.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_93.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_94.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_95.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_96.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_97.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_98.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_99.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_100.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_101.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_102.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_103.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_104.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_105.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_106.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_107.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_108.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_109.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_110.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_111.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_112.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_113.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_114.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_115.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_116.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_117.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_118.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_119.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_120.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_121.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_122.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_123.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_124.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_125.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_126.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_127.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_128.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_129.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_130.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_131.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_132.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_133.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_134.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_135.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_136.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_137.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_138.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_139.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_140.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_141.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_142.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_143.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_144.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_145.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_146.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_147.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_148.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_149.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_150.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_151.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_152.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_153.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_154.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_155.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_156.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_157.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_158.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_159.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_160.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_161.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_162.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_163.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_164.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_165.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_166.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_167.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_168.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_169.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_170.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_171.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_172.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_173.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_174.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_175.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_176.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_177.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_178.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_179.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_180.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_181.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_182.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_183.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_184.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_185.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_186.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./MovementAAL/dataset/MovementAAL_RSS_187.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_188.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_189.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_190.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_191.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_192.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_193.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_194.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_195.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_196.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_197.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_198.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_199.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_200.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_201.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_202.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_203.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_204.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_205.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_206.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_207.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_208.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_209.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_210.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_211.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_212.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_213.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_214.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_215.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_216.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_217.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_218.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_219.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_220.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_221.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_222.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_223.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_224.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_225.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_226.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_227.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_228.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_229.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_230.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_231.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_232.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_233.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_234.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_235.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_236.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_237.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_238.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_239.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_240.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_241.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_242.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_243.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_244.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_245.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_246.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_247.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_248.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_249.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_250.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_251.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_252.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_253.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_254.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_255.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_256.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_257.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_258.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_259.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_260.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_261.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_262.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_263.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_264.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_265.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_266.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_267.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_268.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_269.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_270.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_271.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_272.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_273.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_274.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_275.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_276.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_277.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_278.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_279.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_280.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_281.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_282.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_283.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_284.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_285.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_286.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_287.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_288.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_289.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_290.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_291.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_292.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_293.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_294.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_295.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_296.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_297.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_298.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_299.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_300.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_301.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_302.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_303.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_304.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_305.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_306.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_307.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_308.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_309.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_310.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_311.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_312.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_313.csv\n",
      "./MovementAAL/dataset/MovementAAL_RSS_314.csv\n"
     ]
    }
   ],
   "source": [
    "path = './MovementAAL/dataset/MovementAAL_RSS_'\n",
    "sequences = list()\n",
    "for i in range(1,315):\n",
    "    file_path = path + str(i) + '.csv'\n",
    "    print(file_path)\n",
    "    df = pd.read_csv(file_path, header=0)\n",
    "    values = df.values\n",
    "    sequences.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = pd.read_csv('./MovementAAL/dataset/MovementAAL_target.csv')\n",
    "targets = targets.values[:,1]\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequences[313]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.read_csv('./MovementAAL/groups/MovementAAL_DatasetGroup.csv', header=0)\n",
    "groups = groups.values[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    314.000000\n",
       "mean      42.028662\n",
       "std       16.185303\n",
       "min       19.000000\n",
       "25%       26.000000\n",
       "50%       41.000000\n",
       "75%       56.000000\n",
       "max      129.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_sequences = []\n",
    "for one_seq in sequences:\n",
    "    len_sequences.append(len(one_seq))\n",
    "pd.Series(len_sequences).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding the sequence with the values in last row to max length\n",
    "to_pad = 129\n",
    "new_seq = []\n",
    "for one_seq in sequences:\n",
    "    len_one_seq = len(one_seq)\n",
    "    last_val = one_seq[-1]\n",
    "    n = to_pad - len_one_seq\n",
    "   \n",
    "    to_concat = np.repeat(one_seq[-1], n).reshape(4, n).transpose()\n",
    "    new_one_seq = np.concatenate([one_seq, to_concat])\n",
    "    new_seq.append(new_one_seq)\n",
    "final_seq = np.stack(new_seq)\n",
    "\n",
    "#truncate the sequence to length 60\n",
    "from keras.preprocessing import sequence\n",
    "seq_len = 60\n",
    "final_seq=sequence.pad_sequences(final_seq, maxlen=seq_len, padding='post', dtype='float', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 60, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [final_seq[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "validation = [final_seq[i] for i in range(len(groups)) if groups[i]==1]\n",
    "test = [final_seq[i] for i in range(len(groups)) if groups[i]==3]\n",
    "\n",
    "train_target = [targets[i] for i in range(len(groups)) if (groups[i]==2)]\n",
    "validation_target = [targets[i] for i in range(len(groups)) if groups[i]==1]\n",
    "test_target = [targets[i] for i in range(len(groups)) if groups[i]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "validation = np.array(validation)\n",
    "test = np.array(test)\n",
    "\n",
    "train_target = np.array(train_target)\n",
    "train_target = (train_target+1)/2\n",
    "train_target=np.reshape(train_target,(-1,1))\n",
    "\n",
    "validation_target = np.array(validation_target)\n",
    "validation_target = (validation_target+1)/2\n",
    "validation_target=np.reshape(validation_target,(-1,1))\n",
    "\n",
    "test_target = np.array(test_target)\n",
    "test_target = (test_target+1)/2\n",
    "test_target=np.reshape(test_target,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((106, 60, 4), (104, 60, 4), (104, 60, 4), (106, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validation.shape, test.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRY1: Building time series classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcfly\n",
    "import mcfly, os\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set maximum kernel size for InceptionTime models to number of timesteps.\n",
      "Set maximum kernel size for InceptionTime models to number of timesteps.\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_target.shape[1]\n",
    "metric = 'accuracy'\n",
    "models = mcfly.modelgen.generate_models(train.shape,\n",
    "                                        number_of_classes=num_classes,\n",
    "                                        number_of_models = 8,\n",
    "                                        metrics=[metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 0\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.005481464347736465, 'regularization_rate': 0.010209289921137055, 'filters': array([ 57,  73,  41, 100,  30,  47]), 'fc_hidden_nodes': 689}\n",
      " \n",
      "Model description:\n",
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_602 (Bat (None, 60, 4)             16        \n",
      "_________________________________________________________________\n",
      "conv1d_849 (Conv1D)          (None, 60, 57)            741       \n",
      "_________________________________________________________________\n",
      "batch_normalization_603 (Bat (None, 60, 57)            228       \n",
      "_________________________________________________________________\n",
      "activation_367 (Activation)  (None, 60, 57)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_850 (Conv1D)          (None, 60, 73)            12556     \n",
      "_________________________________________________________________\n",
      "batch_normalization_604 (Bat (None, 60, 73)            292       \n",
      "_________________________________________________________________\n",
      "activation_368 (Activation)  (None, 60, 73)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_851 (Conv1D)          (None, 60, 41)            9020      \n",
      "_________________________________________________________________\n",
      "batch_normalization_605 (Bat (None, 60, 41)            164       \n",
      "_________________________________________________________________\n",
      "activation_369 (Activation)  (None, 60, 41)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_852 (Conv1D)          (None, 60, 100)           12400     \n",
      "_________________________________________________________________\n",
      "batch_normalization_606 (Bat (None, 60, 100)           400       \n",
      "_________________________________________________________________\n",
      "activation_370 (Activation)  (None, 60, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_853 (Conv1D)          (None, 60, 30)            9030      \n",
      "_________________________________________________________________\n",
      "batch_normalization_607 (Bat (None, 60, 30)            120       \n",
      "_________________________________________________________________\n",
      "activation_371 (Activation)  (None, 60, 30)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_854 (Conv1D)          (None, 60, 47)            4277      \n",
      "_________________________________________________________________\n",
      "batch_normalization_608 (Bat (None, 60, 47)            188       \n",
      "_________________________________________________________________\n",
      "activation_372 (Activation)  (None, 60, 47)            0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 2820)              0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 689)               1943669   \n",
      "_________________________________________________________________\n",
      "activation_373 (Activation)  (None, 689)               0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 1)                 690       \n",
      "_________________________________________________________________\n",
      "batch_normalization_609 (Bat (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_374 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,993,795\n",
      "Trainable params: 1,993,089\n",
      "Non-trainable params: 706\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 1\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.0394693672382836, 'regularization_rate': 0.002879158913712458, 'network_depth': 5, 'min_filters_number': 83, 'max_kernel_size': 15}\n",
      " \n",
      "Model description:\n",
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           [(None, 60, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_610 (BatchN (None, 60, 4)        16          input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_855 (Conv1D)             (None, 60, 83)       5063        batch_normalization_610[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_611 (BatchN (None, 60, 83)       332         conv1d_855[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_195 (ReLU)                (None, 60, 83)       0           batch_normalization_611[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_856 (Conv1D)             (None, 60, 83)       103418      re_lu_195[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_612 (BatchN (None, 60, 83)       332         conv1d_856[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_196 (ReLU)                (None, 60, 83)       0           batch_normalization_612[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_857 (Conv1D)             (None, 60, 83)       103418      re_lu_196[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_613 (BatchN (None, 60, 83)       332         conv1d_857[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_197 (ReLU)                (None, 60, 83)       0           batch_normalization_613[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_858 (Conv1D)             (None, 60, 83)       6972        re_lu_197[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 60, 83)       0           re_lu_197[0][0]                  \n",
      "                                                                 conv1d_858[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_859 (Conv1D)             (None, 60, 117)      97227       add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_614 (BatchN (None, 60, 117)      468         conv1d_859[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_198 (ReLU)                (None, 60, 117)      0           batch_normalization_614[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_860 (Conv1D)             (None, 60, 117)      137007      re_lu_198[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_615 (BatchN (None, 60, 117)      468         conv1d_860[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_199 (ReLU)                (None, 60, 117)      0           batch_normalization_615[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_861 (Conv1D)             (None, 60, 117)      137007      re_lu_199[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_616 (BatchN (None, 60, 117)      468         conv1d_861[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_200 (ReLU)                (None, 60, 117)      0           batch_normalization_616[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_862 (Conv1D)             (None, 60, 117)      13806       re_lu_200[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 60, 117)      0           re_lu_200[0][0]                  \n",
      "                                                                 conv1d_862[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_863 (Conv1D)             (None, 60, 165)      135300      add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_617 (BatchN (None, 60, 165)      660         conv1d_863[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_201 (ReLU)                (None, 60, 165)      0           batch_normalization_617[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_864 (Conv1D)             (None, 60, 165)      190740      re_lu_201[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_618 (BatchN (None, 60, 165)      660         conv1d_864[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_202 (ReLU)                (None, 60, 165)      0           batch_normalization_618[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_865 (Conv1D)             (None, 60, 165)      190740      re_lu_202[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_619 (BatchN (None, 60, 165)      660         conv1d_865[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_203 (ReLU)                (None, 60, 165)      0           batch_normalization_619[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_866 (Conv1D)             (None, 60, 165)      27390       re_lu_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 60, 165)      0           re_lu_203[0][0]                  \n",
      "                                                                 conv1d_866[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_867 (Conv1D)             (None, 60, 232)      191632      add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_620 (BatchN (None, 60, 232)      928         conv1d_867[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_204 (ReLU)                (None, 60, 232)      0           batch_normalization_620[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_868 (Conv1D)             (None, 60, 232)      269352      re_lu_204[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_621 (BatchN (None, 60, 232)      928         conv1d_868[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_205 (ReLU)                (None, 60, 232)      0           batch_normalization_621[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_869 (Conv1D)             (None, 60, 232)      269352      re_lu_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_622 (BatchN (None, 60, 232)      928         conv1d_869[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_206 (ReLU)                (None, 60, 232)      0           batch_normalization_622[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_870 (Conv1D)             (None, 60, 232)      54056       re_lu_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 60, 232)      0           re_lu_206[0][0]                  \n",
      "                                                                 conv1d_870[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_871 (Conv1D)             (None, 60, 328)      228616      add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_623 (BatchN (None, 60, 328)      1312        conv1d_871[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_207 (ReLU)                (None, 60, 328)      0           batch_normalization_623[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_872 (Conv1D)             (None, 60, 328)      323080      re_lu_207[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_624 (BatchN (None, 60, 328)      1312        conv1d_872[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_208 (ReLU)                (None, 60, 328)      0           batch_normalization_624[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_873 (Conv1D)             (None, 60, 328)      323080      re_lu_208[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_625 (BatchN (None, 60, 328)      1312        conv1d_873[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_209 (ReLU)                (None, 60, 328)      0           batch_normalization_625[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_874 (Conv1D)             (None, 60, 328)      107912      re_lu_209[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 60, 328)      0           re_lu_209[0][0]                  \n",
      "                                                                 conv1d_874[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_40 (Gl (None, 328)          0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 1)            329         global_average_pooling1d_40[0][0]\n",
      "==================================================================================================\n",
      "Total params: 2,926,613\n",
      "Trainable params: 2,921,055\n",
      "Non-trainable params: 5,558\n",
      "__________________________________________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "ResNet\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 2\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.016768945015015333, 'regularization_rate': 0.0022981482466674346, 'network_depth': 3, 'filters_number': 78, 'max_kernel_size': 16}\n",
      " \n",
      "Model description:\n",
      "Model: \"model_41\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_42 (InputLayer)           [(None, 60, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_626 (BatchN (None, 60, 4)        16          input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_875 (Conv1D)             (None, 60, 32)       128         batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling1D) (None, 60, 4)        0           batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_876 (Conv1D)             (None, 60, 78)       39936       conv1d_875[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_877 (Conv1D)             (None, 60, 78)       19968       conv1d_875[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_878 (Conv1D)             (None, 60, 78)       9984        conv1d_875[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_879 (Conv1D)             (None, 60, 78)       312         max_pooling1d_96[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 60, 312)      0           conv1d_876[0][0]                 \n",
      "                                                                 conv1d_877[0][0]                 \n",
      "                                                                 conv1d_878[0][0]                 \n",
      "                                                                 conv1d_879[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_627 (BatchN (None, 60, 312)      1248        concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_375 (Activation)     (None, 60, 312)      0           batch_normalization_627[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_880 (Conv1D)             (None, 60, 32)       9984        activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling1D) (None, 60, 312)      0           activation_375[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_881 (Conv1D)             (None, 60, 78)       39936       conv1d_880[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_882 (Conv1D)             (None, 60, 78)       19968       conv1d_880[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_883 (Conv1D)             (None, 60, 78)       9984        conv1d_880[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_884 (Conv1D)             (None, 60, 78)       24336       max_pooling1d_97[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 60, 312)      0           conv1d_881[0][0]                 \n",
      "                                                                 conv1d_882[0][0]                 \n",
      "                                                                 conv1d_883[0][0]                 \n",
      "                                                                 conv1d_884[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_628 (BatchN (None, 60, 312)      1248        concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_376 (Activation)     (None, 60, 312)      0           batch_normalization_628[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_885 (Conv1D)             (None, 60, 32)       9984        activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling1D) (None, 60, 312)      0           activation_376[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_886 (Conv1D)             (None, 60, 78)       39936       conv1d_885[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_887 (Conv1D)             (None, 60, 78)       19968       conv1d_885[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_888 (Conv1D)             (None, 60, 78)       9984        conv1d_885[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_889 (Conv1D)             (None, 60, 78)       24336       max_pooling1d_98[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 60, 312)      0           conv1d_886[0][0]                 \n",
      "                                                                 conv1d_887[0][0]                 \n",
      "                                                                 conv1d_888[0][0]                 \n",
      "                                                                 conv1d_889[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_890 (Conv1D)             (None, 60, 312)      1248        batch_normalization_626[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_629 (BatchN (None, 60, 312)      1248        concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_630 (BatchN (None, 60, 312)      1248        conv1d_890[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, 60, 312)      0           batch_normalization_629[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_96 (Add)                    (None, 60, 312)      0           batch_normalization_630[0][0]    \n",
      "                                                                 activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, 60, 312)      0           add_96[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_41 (Gl (None, 312)          0           activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 1)            313         global_average_pooling1d_41[0][0]\n",
      "==================================================================================================\n",
      "Total params: 285,313\n",
      "Trainable params: 282,809\n",
      "Non-trainable params: 2,504\n",
      "__________________________________________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "InceptionTime\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 3\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.013689688066052806, 'regularization_rate': 0.04481465394760804, 'filters': [90, 62, 86], 'lstm_dims': [14, 100, 73]}\n",
      " \n",
      "Model description:\n",
      "Model: \"sequential_41\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_631 (Bat (None, 60, 4)             16        \n",
      "_________________________________________________________________\n",
      "reshape_40 (Reshape)         (None, 60, 4, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 60, 4, 90)         360       \n",
      "_________________________________________________________________\n",
      "batch_normalization_632 (Bat (None, 60, 4, 90)         360       \n",
      "_________________________________________________________________\n",
      "activation_379 (Activation)  (None, 60, 4, 90)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 60, 4, 62)         16802     \n",
      "_________________________________________________________________\n",
      "batch_normalization_633 (Bat (None, 60, 4, 62)         248       \n",
      "_________________________________________________________________\n",
      "activation_380 (Activation)  (None, 60, 4, 62)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_104 (Conv2D)          (None, 60, 4, 86)         16082     \n",
      "_________________________________________________________________\n",
      "batch_normalization_634 (Bat (None, 60, 4, 86)         344       \n",
      "_________________________________________________________________\n",
      "activation_381 (Activation)  (None, 60, 4, 86)         0         \n",
      "_________________________________________________________________\n",
      "reshape_41 (Reshape)         (None, 60, 344)           0         \n",
      "_________________________________________________________________\n",
      "lstm_62 (LSTM)               (None, 60, 14)            20104     \n",
      "_________________________________________________________________\n",
      "lstm_63 (LSTM)               (None, 60, 100)           46000     \n",
      "_________________________________________________________________\n",
      "lstm_64 (LSTM)               (None, 60, 73)            50808     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 60, 73)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 60, 1)             74        \n",
      "_________________________________________________________________\n",
      "activation_382 (Activation)  (None, 60, 1)             0         \n",
      "_________________________________________________________________\n",
      "lambda_20 (Lambda)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 151,198\n",
      "Trainable params: 150,714\n",
      "Non-trainable params: 484\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 4\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.02183138953555479, 'regularization_rate': 0.008923210639822017, 'filters': array([ 60,  25,  18,  27,  32,  83,  67, 100,  72]), 'fc_hidden_nodes': 1117}\n",
      " \n",
      "Model description:\n",
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_635 (Bat (None, 60, 4)             16        \n",
      "_________________________________________________________________\n",
      "conv1d_891 (Conv1D)          (None, 60, 60)            780       \n",
      "_________________________________________________________________\n",
      "batch_normalization_636 (Bat (None, 60, 60)            240       \n",
      "_________________________________________________________________\n",
      "activation_383 (Activation)  (None, 60, 60)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_892 (Conv1D)          (None, 60, 25)            4525      \n",
      "_________________________________________________________________\n",
      "batch_normalization_637 (Bat (None, 60, 25)            100       \n",
      "_________________________________________________________________\n",
      "activation_384 (Activation)  (None, 60, 25)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_893 (Conv1D)          (None, 60, 18)            1368      \n",
      "_________________________________________________________________\n",
      "batch_normalization_638 (Bat (None, 60, 18)            72        \n",
      "_________________________________________________________________\n",
      "activation_385 (Activation)  (None, 60, 18)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_894 (Conv1D)          (None, 60, 27)            1485      \n",
      "_________________________________________________________________\n",
      "batch_normalization_639 (Bat (None, 60, 27)            108       \n",
      "_________________________________________________________________\n",
      "activation_386 (Activation)  (None, 60, 27)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_895 (Conv1D)          (None, 60, 32)            2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_640 (Bat (None, 60, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_387 (Activation)  (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_896 (Conv1D)          (None, 60, 83)            8051      \n",
      "_________________________________________________________________\n",
      "batch_normalization_641 (Bat (None, 60, 83)            332       \n",
      "_________________________________________________________________\n",
      "activation_388 (Activation)  (None, 60, 83)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_897 (Conv1D)          (None, 60, 67)            16750     \n",
      "_________________________________________________________________\n",
      "batch_normalization_642 (Bat (None, 60, 67)            268       \n",
      "_________________________________________________________________\n",
      "activation_389 (Activation)  (None, 60, 67)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_898 (Conv1D)          (None, 60, 100)           20200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_643 (Bat (None, 60, 100)           400       \n",
      "_________________________________________________________________\n",
      "activation_390 (Activation)  (None, 60, 100)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_899 (Conv1D)          (None, 60, 72)            21672     \n",
      "_________________________________________________________________\n",
      "batch_normalization_644 (Bat (None, 60, 72)            288       \n",
      "_________________________________________________________________\n",
      "activation_391 (Activation)  (None, 60, 72)            0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 4320)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 1117)              4826557   \n",
      "_________________________________________________________________\n",
      "activation_392 (Activation)  (None, 1117)              0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 1)                 1118      \n",
      "_________________________________________________________________\n",
      "batch_normalization_645 (Bat (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "activation_393 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 4,907,086\n",
      "Trainable params: 4,906,108\n",
      "Non-trainable params: 978\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "CNN\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 5\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.022294114160952016, 'regularization_rate': 0.00010476135731378123, 'network_depth': 4, 'min_filters_number': 40, 'max_kernel_size': 20}\n",
      " \n",
      "Model description:\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_43 (InputLayer)           [(None, 60, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_646 (BatchN (None, 60, 4)        16          input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_900 (Conv1D)             (None, 60, 40)       3240        batch_normalization_646[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_647 (BatchN (None, 60, 40)       160         conv1d_900[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_210 (ReLU)                (None, 60, 40)       0           batch_normalization_647[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_901 (Conv1D)             (None, 60, 40)       32040       re_lu_210[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_648 (BatchN (None, 60, 40)       160         conv1d_901[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_211 (ReLU)                (None, 60, 40)       0           batch_normalization_648[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_902 (Conv1D)             (None, 60, 40)       32040       re_lu_211[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_649 (BatchN (None, 60, 40)       160         conv1d_902[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_212 (ReLU)                (None, 60, 40)       0           batch_normalization_649[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_903 (Conv1D)             (None, 60, 40)       1640        re_lu_212[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_97 (Add)                    (None, 60, 40)       0           re_lu_212[0][0]                  \n",
      "                                                                 conv1d_903[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_904 (Conv1D)             (None, 60, 56)       31416       add_97[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_650 (BatchN (None, 60, 56)       224         conv1d_904[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_213 (ReLU)                (None, 60, 56)       0           batch_normalization_650[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_905 (Conv1D)             (None, 60, 56)       43960       re_lu_213[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_651 (BatchN (None, 60, 56)       224         conv1d_905[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_214 (ReLU)                (None, 60, 56)       0           batch_normalization_651[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_906 (Conv1D)             (None, 60, 56)       43960       re_lu_214[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_652 (BatchN (None, 60, 56)       224         conv1d_906[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_215 (ReLU)                (None, 60, 56)       0           batch_normalization_652[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_907 (Conv1D)             (None, 60, 56)       3192        re_lu_215[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_98 (Add)                    (None, 60, 56)       0           re_lu_215[0][0]                  \n",
      "                                                                 conv1d_907[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_908 (Conv1D)             (None, 60, 79)       44319       add_98[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_653 (BatchN (None, 60, 79)       316         conv1d_908[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_216 (ReLU)                (None, 60, 79)       0           batch_normalization_653[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_909 (Conv1D)             (None, 60, 79)       62489       re_lu_216[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_654 (BatchN (None, 60, 79)       316         conv1d_909[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_217 (ReLU)                (None, 60, 79)       0           batch_normalization_654[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_910 (Conv1D)             (None, 60, 79)       62489       re_lu_217[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_655 (BatchN (None, 60, 79)       316         conv1d_910[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_218 (ReLU)                (None, 60, 79)       0           batch_normalization_655[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_911 (Conv1D)             (None, 60, 79)       6320        re_lu_218[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_99 (Add)                    (None, 60, 79)       0           re_lu_218[0][0]                  \n",
      "                                                                 conv1d_911[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_912 (Conv1D)             (None, 60, 112)      62048       add_99[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_656 (BatchN (None, 60, 112)      448         conv1d_912[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_219 (ReLU)                (None, 60, 112)      0           batch_normalization_656[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_913 (Conv1D)             (None, 60, 112)      87920       re_lu_219[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_657 (BatchN (None, 60, 112)      448         conv1d_913[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_220 (ReLU)                (None, 60, 112)      0           batch_normalization_657[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_914 (Conv1D)             (None, 60, 112)      87920       re_lu_220[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_658 (BatchN (None, 60, 112)      448         conv1d_914[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_221 (ReLU)                (None, 60, 112)      0           batch_normalization_658[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_915 (Conv1D)             (None, 60, 112)      12656       re_lu_221[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_100 (Add)                   (None, 60, 112)      0           re_lu_221[0][0]                  \n",
      "                                                                 conv1d_915[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_42 (Gl (None, 112)          0           add_100[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 1)            113         global_average_pooling1d_42[0][0]\n",
      "==================================================================================================\n",
      "Total params: 621,222\n",
      "Trainable params: 619,492\n",
      "Non-trainable params: 1,730\n",
      "__________________________________________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "ResNet\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 6\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.005216294589208116, 'regularization_rate': 0.004895062158334504, 'filters': [80, 96, 80, 29, 66, 92, 11, 78, 50, 91], 'lstm_dims': [28, 94]}\n",
      " \n",
      "Model description:\n",
      "Model: \"sequential_43\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_659 (Bat (None, 60, 4)             16        \n",
      "_________________________________________________________________\n",
      "reshape_42 (Reshape)         (None, 60, 4, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 60, 4, 80)         320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_660 (Bat (None, 60, 4, 80)         320       \n",
      "_________________________________________________________________\n",
      "activation_394 (Activation)  (None, 60, 4, 80)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 60, 4, 96)         23136     \n",
      "_________________________________________________________________\n",
      "batch_normalization_661 (Bat (None, 60, 4, 96)         384       \n",
      "_________________________________________________________________\n",
      "activation_395 (Activation)  (None, 60, 4, 96)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_107 (Conv2D)          (None, 60, 4, 80)         23120     \n",
      "_________________________________________________________________\n",
      "batch_normalization_662 (Bat (None, 60, 4, 80)         320       \n",
      "_________________________________________________________________\n",
      "activation_396 (Activation)  (None, 60, 4, 80)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_108 (Conv2D)          (None, 60, 4, 29)         6989      \n",
      "_________________________________________________________________\n",
      "batch_normalization_663 (Bat (None, 60, 4, 29)         116       \n",
      "_________________________________________________________________\n",
      "activation_397 (Activation)  (None, 60, 4, 29)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 60, 4, 66)         5808      \n",
      "_________________________________________________________________\n",
      "batch_normalization_664 (Bat (None, 60, 4, 66)         264       \n",
      "_________________________________________________________________\n",
      "activation_398 (Activation)  (None, 60, 4, 66)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_110 (Conv2D)          (None, 60, 4, 92)         18308     \n",
      "_________________________________________________________________\n",
      "batch_normalization_665 (Bat (None, 60, 4, 92)         368       \n",
      "_________________________________________________________________\n",
      "activation_399 (Activation)  (None, 60, 4, 92)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_111 (Conv2D)          (None, 60, 4, 11)         3047      \n",
      "_________________________________________________________________\n",
      "batch_normalization_666 (Bat (None, 60, 4, 11)         44        \n",
      "_________________________________________________________________\n",
      "activation_400 (Activation)  (None, 60, 4, 11)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_112 (Conv2D)          (None, 60, 4, 78)         2652      \n",
      "_________________________________________________________________\n",
      "batch_normalization_667 (Bat (None, 60, 4, 78)         312       \n",
      "_________________________________________________________________\n",
      "activation_401 (Activation)  (None, 60, 4, 78)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 60, 4, 50)         11750     \n",
      "_________________________________________________________________\n",
      "batch_normalization_668 (Bat (None, 60, 4, 50)         200       \n",
      "_________________________________________________________________\n",
      "activation_402 (Activation)  (None, 60, 4, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 60, 4, 91)         13741     \n",
      "_________________________________________________________________\n",
      "batch_normalization_669 (Bat (None, 60, 4, 91)         364       \n",
      "_________________________________________________________________\n",
      "activation_403 (Activation)  (None, 60, 4, 91)         0         \n",
      "_________________________________________________________________\n",
      "reshape_43 (Reshape)         (None, 60, 364)           0         \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 60, 28)            44016     \n",
      "_________________________________________________________________\n",
      "lstm_66 (LSTM)               (None, 60, 94)            46248     \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 60, 94)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 60, 1)             95        \n",
      "_________________________________________________________________\n",
      "activation_404 (Activation)  (None, 60, 1)             0         \n",
      "_________________________________________________________________\n",
      "lambda_21 (Lambda)           (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 201,938\n",
      "Trainable params: 200,584\n",
      "Non-trainable params: 1,354\n",
      "_________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "DeepConvLSTM\n",
      " \n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Model 7\n",
      " \n",
      "Hyperparameters:\n",
      "{'learning_rate': 0.00010433835028846764, 'regularization_rate': 0.0001225346909794931, 'network_depth': 3, 'filters_number': 48, 'max_kernel_size': 31}\n",
      " \n",
      "Model description:\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_44 (InputLayer)           [(None, 60, 4)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_670 (BatchN (None, 60, 4)        16          input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_916 (Conv1D)             (None, 60, 32)       128         batch_normalization_670[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling1D) (None, 60, 4)        0           batch_normalization_670[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_917 (Conv1D)             (None, 60, 48)       47616       conv1d_916[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_918 (Conv1D)             (None, 60, 48)       23040       conv1d_916[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_919 (Conv1D)             (None, 60, 48)       10752       conv1d_916[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_920 (Conv1D)             (None, 60, 48)       192         max_pooling1d_99[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 60, 192)      0           conv1d_917[0][0]                 \n",
      "                                                                 conv1d_918[0][0]                 \n",
      "                                                                 conv1d_919[0][0]                 \n",
      "                                                                 conv1d_920[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_671 (BatchN (None, 60, 192)      768         concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, 60, 192)      0           batch_normalization_671[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_921 (Conv1D)             (None, 60, 32)       6144        activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_100 (MaxPooling1D (None, 60, 192)      0           activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_922 (Conv1D)             (None, 60, 48)       47616       conv1d_921[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_923 (Conv1D)             (None, 60, 48)       23040       conv1d_921[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_924 (Conv1D)             (None, 60, 48)       10752       conv1d_921[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_925 (Conv1D)             (None, 60, 48)       9216        max_pooling1d_100[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 60, 192)      0           conv1d_922[0][0]                 \n",
      "                                                                 conv1d_923[0][0]                 \n",
      "                                                                 conv1d_924[0][0]                 \n",
      "                                                                 conv1d_925[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_672 (BatchN (None, 60, 192)      768         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, 60, 192)      0           batch_normalization_672[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_926 (Conv1D)             (None, 60, 32)       6144        activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_101 (MaxPooling1D (None, 60, 192)      0           activation_406[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_927 (Conv1D)             (None, 60, 48)       47616       conv1d_926[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_928 (Conv1D)             (None, 60, 48)       23040       conv1d_926[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_929 (Conv1D)             (None, 60, 48)       10752       conv1d_926[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_930 (Conv1D)             (None, 60, 48)       9216        max_pooling1d_101[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 60, 192)      0           conv1d_927[0][0]                 \n",
      "                                                                 conv1d_928[0][0]                 \n",
      "                                                                 conv1d_929[0][0]                 \n",
      "                                                                 conv1d_930[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_931 (Conv1D)             (None, 60, 192)      768         batch_normalization_670[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_673 (BatchN (None, 60, 192)      768         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_674 (BatchN (None, 60, 192)      768         conv1d_931[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, 60, 192)      0           batch_normalization_673[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "add_101 (Add)                   (None, 60, 192)      0           batch_normalization_674[0][0]    \n",
      "                                                                 activation_407[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, 60, 192)      0           add_101[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_43 (Gl (None, 192)          0           activation_408[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 1)            193         global_average_pooling1d_43[0][0]\n",
      "==================================================================================================\n",
      "Total params: 279,313\n",
      "Trainable params: 277,769\n",
      "Non-trainable params: 1,544\n",
      "__________________________________________________________________________________________________\n",
      " \n",
      "Model type:\n",
      "InceptionTime\n",
      " \n"
     ]
    }
   ],
   "source": [
    "models_to_print = range(len(models))\n",
    "for i, item in enumerate(models):\n",
    "    if i in models_to_print:\n",
    "        model, params, model_types = item\n",
    "        print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"Model \" + str(i))\n",
    "        print(\" \")\n",
    "        print(\"Hyperparameters:\")\n",
    "        print(params)\n",
    "        print(\" \")\n",
    "        print(\"Model description:\")\n",
    "        model.summary()\n",
    "        print(\" \")\n",
    "        print(\"Model type:\")\n",
    "        print(model_types)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(<tensorflow.python.keras.engine.sequential.Sequential at 0x1c6709f8b20>,\n",
       "  {'learning_rate': 0.005481464347736465,\n",
       "   'regularization_rate': 0.010209289921137055,\n",
       "   'filters': array([ 57,  73,  41, 100,  30,  47]),\n",
       "   'fc_hidden_nodes': 689},\n",
       "  'CNN'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x1c75583c280>,\n",
       "  {'learning_rate': 0.0394693672382836,\n",
       "   'regularization_rate': 0.002879158913712458,\n",
       "   'network_depth': 5,\n",
       "   'min_filters_number': 83,\n",
       "   'max_kernel_size': 15},\n",
       "  'ResNet'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x1c7560a3b20>,\n",
       "  {'learning_rate': 0.016768945015015333,\n",
       "   'regularization_rate': 0.0022981482466674346,\n",
       "   'network_depth': 3,\n",
       "   'filters_number': 78,\n",
       "   'max_kernel_size': 16},\n",
       "  'InceptionTime'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x1c671650940>,\n",
       "  {'learning_rate': 0.013689688066052806,\n",
       "   'regularization_rate': 0.04481465394760804,\n",
       "   'filters': [90, 62, 86],\n",
       "   'lstm_dims': [14, 100, 73]},\n",
       "  'DeepConvLSTM'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x1c7560adcd0>,\n",
       "  {'learning_rate': 0.02183138953555479,\n",
       "   'regularization_rate': 0.008923210639822017,\n",
       "   'filters': array([ 60,  25,  18,  27,  32,  83,  67, 100,  72]),\n",
       "   'fc_hidden_nodes': 1117},\n",
       "  'CNN'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x1c758d93670>,\n",
       "  {'learning_rate': 0.022294114160952016,\n",
       "   'regularization_rate': 0.00010476135731378123,\n",
       "   'network_depth': 4,\n",
       "   'min_filters_number': 40,\n",
       "   'max_kernel_size': 20},\n",
       "  'ResNet'),\n",
       " (<tensorflow.python.keras.engine.sequential.Sequential at 0x1c7589b4ac0>,\n",
       "  {'learning_rate': 0.005216294589208116,\n",
       "   'regularization_rate': 0.004895062158334504,\n",
       "   'filters': [80, 96, 80, 29, 66, 92, 11, 78, 50, 91],\n",
       "   'lstm_dims': [28, 94]},\n",
       "  'DeepConvLSTM'),\n",
       " (<tensorflow.python.keras.engine.training.Model at 0x1c75a8892e0>,\n",
       "  {'learning_rate': 0.00010433835028846764,\n",
       "   'regularization_rate': 0.0001225346909794931,\n",
       "   'network_depth': 3,\n",
       "   'filters_number': 48,\n",
       "   'max_kernel_size': 31},\n",
       "  'InceptionTime')]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory where the results, e.g. json file, will be stored\n",
    "resultpath = os.path.join('.', 'models')\n",
    "if not os.path.exists(resultpath):\n",
    "    os.makedirs(resultpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated models will be trained on subset of the data (subset size: 300).\n",
      "Training model 0 CNN\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\mcfly\\find_architecture.py:134: UserWarning: Argument 'metric' is deprecated and will be ignored.\n",
      "  warnings.warn(\"Argument 'metric' is deprecated and will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 78ms/step - loss: 6.7689 - accuracy: 0.4906 - val_loss: 4.7027 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 4.4956 - accuracy: 0.4906 - val_loss: 3.8453 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 3.2824 - accuracy: 0.4906 - val_loss: 2.3842 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 2.0466 - accuracy: 0.4906 - val_loss: 1.5786 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.3768 - accuracy: 0.4906 - val_loss: 1.0523 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.9135 - accuracy: 0.4906 - val_loss: 0.7289 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.6538 - accuracy: 0.4906 - val_loss: 0.5245 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.4634 - accuracy: 0.4906 - val_loss: 0.3927 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.3603 - accuracy: 0.4906 - val_loss: 0.2922 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2637 - accuracy: 0.4906 - val_loss: 0.2752 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2804 - accuracy: 0.4906 - val_loss: 0.2399 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2119 - accuracy: 0.4906 - val_loss: 0.1915 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1928 - accuracy: 0.4906 - val_loss: 0.1948 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.1874 - accuracy: 0.4906 - val_loss: 0.1694 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1534 - accuracy: 0.4906 - val_loss: 0.1295 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1208 - accuracy: 0.4906 - val_loss: 0.1281 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1283 - accuracy: 0.4906 - val_loss: 0.1088 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0966 - accuracy: 0.4906 - val_loss: 0.0895 - val_accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0993 - accuracy: 0.4906 - val_loss: 0.1339 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1558 - accuracy: 0.4906 - val_loss: 0.2033 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.2042 - accuracy: 0.4906 - val_loss: 0.1947 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1874 - accuracy: 0.4906 - val_loss: 0.1767 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1708 - accuracy: 0.4906 - val_loss: 0.1613 - val_accuracy: 0.5000\n",
      "Epoch 00023: early stopping\n",
      "Training model 1 ResNet\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 2s 272ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 1s 207ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 1s 210ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 1s 208ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 1s 208ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 1s 207ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n",
      "Training model 2 InceptionTime\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 56ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n",
      "Training model 3 DeepConvLSTM\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 237ms/step - loss: 7.1027 - accuracy: 0.4906 - val_loss: 3.5731 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 78ms/step - loss: 3.2570 - accuracy: 0.4906 - val_loss: 2.9815 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 2.7274 - accuracy: 0.4906 - val_loss: 2.1517 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 1.8412 - accuracy: 0.4906 - val_loss: 1.4104 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 1.2625 - accuracy: 0.4906 - val_loss: 1.0376 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 76ms/step - loss: 0.9212 - accuracy: 0.4906 - val_loss: 0.7247 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 80ms/step - loss: 0.6328 - accuracy: 0.4906 - val_loss: 0.4943 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 83ms/step - loss: 0.4346 - accuracy: 0.4906 - val_loss: 0.3409 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 79ms/step - loss: 0.2973 - accuracy: 0.4906 - val_loss: 0.2287 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 1s 91ms/step - loss: 0.1981 - accuracy: 0.4906 - val_loss: 0.1510 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.1301 - accuracy: 0.4906 - val_loss: 0.0980 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.0839 - accuracy: 0.4906 - val_loss: 0.0622 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.0529 - accuracy: 0.4906 - val_loss: 0.0386 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.0326 - accuracy: 0.4906 - val_loss: 0.0235 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.0196 - accuracy: 0.4906 - val_loss: 0.0139 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 1s 100ms/step - loss: 0.0115 - accuracy: 0.4906 - val_loss: 0.0080 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.0066 - accuracy: 0.4906 - val_loss: 0.0045 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.0037 - accuracy: 0.4906 - val_loss: 0.0025 - val_accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 0.0020 - accuracy: 0.4906 - val_loss: 0.0013 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.0010 - accuracy: 0.4906 - val_loss: 6.5945e-04 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 1s 99ms/step - loss: 5.2058e-04 - accuracy: 0.4906 - val_loss: 3.2453e-04 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 106ms/step - loss: 2.5269e-04 - accuracy: 0.4906 - val_loss: 1.5350e-04 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 1.1827e-04 - accuracy: 0.4906 - val_loss: 6.9880e-05 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 1s 112ms/step - loss: 5.3090e-05 - accuracy: 0.4906 - val_loss: 3.0574e-05 - val_accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 1s 107ms/step - loss: 2.3054e-05 - accuracy: 0.4906 - val_loss: 1.3047e-05 - val_accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 9.7985e-06 - accuracy: 0.4906 - val_loss: 5.5878e-06 - val_accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 4.2691e-06 - accuracy: 0.4906 - val_loss: 2.5657e-06 - val_accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 1s 106ms/step - loss: 2.0353e-06 - accuracy: 0.4906 - val_loss: 1.3508e-06 - val_accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 1.1299e-06 - accuracy: 0.4906 - val_loss: 8.3256e-07 - val_accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 7.2380e-07 - accuracy: 0.4906 - val_loss: 5.6765e-07 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 5.0266e-07 - accuracy: 0.4906 - val_loss: 4.0462e-07 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 3.5963e-07 - accuracy: 0.4906 - val_loss: 2.9109e-07 - val_accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 2.5989e-07 - accuracy: 0.4906 - val_loss: 2.1303e-07 - val_accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 1.9163e-07 - accuracy: 0.4906 - val_loss: 1.6085e-07 - val_accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 1.4726e-07 - accuracy: 0.4906 - val_loss: 1.2845e-07 - val_accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 1.2012e-07 - accuracy: 0.4906 - val_loss: 1.0951e-07 - val_accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 1.0467e-07 - accuracy: 0.4906 - val_loss: 9.9161e-08 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 9.6384e-08 - accuracy: 0.4906 - val_loss: 9.3899e-08 - val_accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 9.2268e-08 - accuracy: 0.4906 - val_loss: 9.1391e-08 - val_accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 9.0353e-08 - accuracy: 0.4906 - val_loss: 9.0288e-08 - val_accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.9523e-08 - accuracy: 0.4906 - val_loss: 8.9824e-08 - val_accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.9180e-08 - accuracy: 0.4906 - val_loss: 8.9633e-08 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.9034e-08 - accuracy: 0.4906 - val_loss: 8.9546e-08 - val_accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.8964e-08 - accuracy: 0.4906 - val_loss: 8.9497e-08 - val_accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.8922e-08 - accuracy: 0.4906 - val_loss: 8.9464e-08 - val_accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.8893e-08 - accuracy: 0.4906 - val_loss: 8.9441e-08 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.8873e-08 - accuracy: 0.4906 - val_loss: 8.9426e-08 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8860e-08 - accuracy: 0.4906 - val_loss: 8.9417e-08 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.8852e-08 - accuracy: 0.4906 - val_loss: 8.9412e-08 - val_accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.8848e-08 - accuracy: 0.4906 - val_loss: 8.9409e-08 - val_accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8846e-08 - accuracy: 0.4906 - val_loss: 8.9408e-08 - val_accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 1s 88ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 1s 86ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 1s 89ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 1s 87ms/step - loss: 8.8845e-08 - accuracy: 0.4906 - val_loss: 8.9407e-08 - val_accuracy: 0.5000\n",
      "Epoch 00065: early stopping\n",
      "Training model 4 CNN\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 21.9444 - accuracy: 0.4906 - val_loss: 39.3536 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 33.8144 - accuracy: 0.4906 - val_loss: 21.4295 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 16.7029 - accuracy: 0.4906 - val_loss: 10.6435 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 72ms/step - loss: 8.7168 - accuracy: 0.4906 - val_loss: 6.2409 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 5.1373 - accuracy: 0.4906 - val_loss: 3.6919 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 3.2107 - accuracy: 0.4906 - val_loss: 2.8950 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 2.4502 - accuracy: 0.4906 - val_loss: 1.9553 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 1.7722 - accuracy: 0.4906 - val_loss: 1.6975 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 1.4015 - accuracy: 0.4906 - val_loss: 1.0421 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 1.1519 - accuracy: 0.4906 - val_loss: 3.6546 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 3.0809 - accuracy: 0.4906 - val_loss: 1.5442 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 72ms/step - loss: 1.7713 - accuracy: 0.4906 - val_loss: 1.9836 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 75ms/step - loss: 1.7166 - accuracy: 0.4906 - val_loss: 1.4877 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 1.7819 - accuracy: 0.4906 - val_loss: 1.8650 - val_accuracy: 0.5000\n",
      "Epoch 00014: early stopping\n",
      "Training model 5 ResNet\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 73ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 74ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n",
      "Training model 6 DeepConvLSTM\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 246ms/step - loss: 2.5958 - accuracy: 0.4906 - val_loss: 1.6567 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 1s 123ms/step - loss: 1.3119 - accuracy: 0.4906 - val_loss: 0.8461 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.6949 - accuracy: 0.4906 - val_loss: 0.5016 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.4432 - accuracy: 0.4906 - val_loss: 0.3669 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.3394 - accuracy: 0.4906 - val_loss: 0.2969 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.2761 - accuracy: 0.4906 - val_loss: 0.2413 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.2238 - accuracy: 0.4906 - val_loss: 0.1956 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 0.1825 - accuracy: 0.4906 - val_loss: 0.1620 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.1527 - accuracy: 0.4906 - val_loss: 0.1381 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 1s 129ms/step - loss: 0.1313 - accuracy: 0.4906 - val_loss: 0.1201 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.1145 - accuracy: 0.4906 - val_loss: 0.1052 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.1004 - accuracy: 0.4906 - val_loss: 0.0925 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0885 - accuracy: 0.4906 - val_loss: 0.0817 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0782 - accuracy: 0.4906 - val_loss: 0.0723 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.0692 - accuracy: 0.4906 - val_loss: 0.0640 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0613 - accuracy: 0.4906 - val_loss: 0.0567 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0543 - accuracy: 0.4906 - val_loss: 0.0501 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0480 - accuracy: 0.4906 - val_loss: 0.0443 - val_accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0424 - accuracy: 0.4906 - val_loss: 0.0391 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0374 - accuracy: 0.4906 - val_loss: 0.0344 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0329 - accuracy: 0.4906 - val_loss: 0.0303 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0289 - accuracy: 0.4906 - val_loss: 0.0266 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0254 - accuracy: 0.4906 - val_loss: 0.0234 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0223 - accuracy: 0.4906 - val_loss: 0.0205 - val_accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0195 - accuracy: 0.4906 - val_loss: 0.0179 - val_accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0171 - accuracy: 0.4906 - val_loss: 0.0156 - val_accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 0.0149 - accuracy: 0.4906 - val_loss: 0.0136 - val_accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0130 - accuracy: 0.4906 - val_loss: 0.0119 - val_accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0113 - accuracy: 0.4906 - val_loss: 0.0103 - val_accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0098 - accuracy: 0.4906 - val_loss: 0.0089 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0085 - accuracy: 0.4906 - val_loss: 0.0077 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.0074 - accuracy: 0.4906 - val_loss: 0.0067 - val_accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0064 - accuracy: 0.4906 - val_loss: 0.0058 - val_accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0055 - accuracy: 0.4906 - val_loss: 0.0050 - val_accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0047 - accuracy: 0.4906 - val_loss: 0.0043 - val_accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0041 - accuracy: 0.4906 - val_loss: 0.0037 - val_accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0035 - accuracy: 0.4906 - val_loss: 0.0032 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0030 - accuracy: 0.4906 - val_loss: 0.0027 - val_accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0025 - accuracy: 0.4906 - val_loss: 0.0023 - val_accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 0.0022 - accuracy: 0.4906 - val_loss: 0.0020 - val_accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0019 - accuracy: 0.4906 - val_loss: 0.0017 - val_accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0016 - accuracy: 0.4906 - val_loss: 0.0014 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 0.0013 - accuracy: 0.4906 - val_loss: 0.0012 - val_accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0011 - accuracy: 0.4906 - val_loss: 0.0010 - val_accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 9.6009e-04 - accuracy: 0.4906 - val_loss: 8.6136e-04 - val_accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 8.1086e-04 - accuracy: 0.4906 - val_loss: 7.2663e-04 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 6.8360e-04 - accuracy: 0.4906 - val_loss: 6.1188e-04 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 126ms/step - loss: 5.7529e-04 - accuracy: 0.4906 - val_loss: 5.1433e-04 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 4.8327e-04 - accuracy: 0.4906 - val_loss: 4.3156e-04 - val_accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 4.0525e-04 - accuracy: 0.4906 - val_loss: 3.6147e-04 - val_accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 3.3921e-04 - accuracy: 0.4906 - val_loss: 3.0221e-04 - val_accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 2.8343e-04 - accuracy: 0.4906 - val_loss: 2.5222e-04 - val_accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 2.3640e-04 - accuracy: 0.4906 - val_loss: 2.1013e-04 - val_accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 1.9682e-04 - accuracy: 0.4906 - val_loss: 1.7474e-04 - val_accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.6357e-04 - accuracy: 0.4906 - val_loss: 1.4506e-04 - val_accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.3570e-04 - accuracy: 0.4906 - val_loss: 1.2020e-04 - val_accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.1238e-04 - accuracy: 0.4906 - val_loss: 9.9432e-05 - val_accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 9.2904e-05 - accuracy: 0.4906 - val_loss: 8.2104e-05 - val_accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 7.6667e-05 - accuracy: 0.4906 - val_loss: 6.7677e-05 - val_accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 1s 137ms/step - loss: 6.3156e-05 - accuracy: 0.4906 - val_loss: 5.5688e-05 - val_accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 5.1936e-05 - accuracy: 0.4906 - val_loss: 4.5743e-05 - val_accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 4.2635e-05 - accuracy: 0.4906 - val_loss: 3.7509e-05 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 3.4940e-05 - accuracy: 0.4906 - val_loss: 3.0705e-05 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 2.8585e-05 - accuracy: 0.4906 - val_loss: 2.5093e-05 - val_accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 2.3347e-05 - accuracy: 0.4906 - val_loss: 2.0473e-05 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.9038e-05 - accuracy: 0.4906 - val_loss: 1.6677e-05 - val_accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.5499e-05 - accuracy: 0.4906 - val_loss: 1.3564e-05 - val_accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.2601e-05 - accuracy: 0.4906 - val_loss: 1.1015e-05 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.0228e-05 - accuracy: 0.4906 - val_loss: 8.9394e-06 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 8.2943e-06 - accuracy: 0.4906 - val_loss: 7.2366e-06 - val_accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 6.7120e-06 - accuracy: 0.4906 - val_loss: 5.8568e-06 - val_accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 5.4284e-06 - accuracy: 0.4906 - val_loss: 4.7277e-06 - val_accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 4.3824e-06 - accuracy: 0.4906 - val_loss: 3.8163e-06 - val_accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 3.5362e-06 - accuracy: 0.4906 - val_loss: 3.0783e-06 - val_accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 1s 124ms/step - loss: 2.8518e-06 - accuracy: 0.4906 - val_loss: 2.4821e-06 - val_accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 2.2994e-06 - accuracy: 0.4906 - val_loss: 2.0034e-06 - val_accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.8573e-06 - accuracy: 0.4906 - val_loss: 1.6181e-06 - val_accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 1s 128ms/step - loss: 1.4976e-06 - accuracy: 0.4906 - val_loss: 1.3051e-06 - val_accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.2093e-06 - accuracy: 0.4906 - val_loss: 1.0553e-06 - val_accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 9.7865e-07 - accuracy: 0.4906 - val_loss: 8.5773e-07 - val_accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 7.9781e-07 - accuracy: 0.4906 - val_loss: 7.0526e-07 - val_accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 6.6327e-07 - accuracy: 0.4906 - val_loss: 5.9022e-07 - val_accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 5.5042e-07 - accuracy: 0.4906 - val_loss: 4.7984e-07 - val_accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 4.4620e-07 - accuracy: 0.4906 - val_loss: 4.0125e-07 - val_accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 3.7146e-07 - accuracy: 0.4906 - val_loss: 3.2760e-07 - val_accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 3.0756e-07 - accuracy: 0.4906 - val_loss: 2.7551e-07 - val_accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 2.6297e-07 - accuracy: 0.4906 - val_loss: 2.3616e-07 - val_accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 2.2784e-07 - accuracy: 0.4906 - val_loss: 2.0599e-07 - val_accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 2.0198e-07 - accuracy: 0.4906 - val_loss: 1.8939e-07 - val_accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.7849e-07 - accuracy: 0.4906 - val_loss: 1.6478e-07 - val_accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.5924e-07 - accuracy: 0.4906 - val_loss: 1.4822e-07 - val_accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.4567e-07 - accuracy: 0.4906 - val_loss: 1.3428e-07 - val_accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.3077e-07 - accuracy: 0.4906 - val_loss: 1.2188e-07 - val_accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.2249e-07 - accuracy: 0.4906 - val_loss: 1.1870e-07 - val_accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.1813e-07 - accuracy: 0.4906 - val_loss: 1.1295e-07 - val_accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.1377e-07 - accuracy: 0.4906 - val_loss: 1.0741e-07 - val_accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.0607e-07 - accuracy: 0.4906 - val_loss: 1.0234e-07 - val_accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.0274e-07 - accuracy: 0.4906 - val_loss: 1.0575e-07 - val_accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 1.0092e-07 - accuracy: 0.4906 - val_loss: 9.8752e-08 - val_accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 9.7044e-08 - accuracy: 0.4906 - val_loss: 9.7047e-08 - val_accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 9.8884e-08 - accuracy: 0.4906 - val_loss: 9.5750e-08 - val_accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 9.5209e-08 - accuracy: 0.4906 - val_loss: 9.2926e-08 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 9.2822e-08 - accuracy: 0.4906 - val_loss: 9.2045e-08 - val_accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 9.2944e-08 - accuracy: 0.4906 - val_loss: 1.0578e-07 - val_accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 9.9877e-08 - accuracy: 0.4906 - val_loss: 9.3663e-08 - val_accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 1s 125ms/step - loss: 9.4507e-08 - accuracy: 0.4906 - val_loss: 1.0106e-07 - val_accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 9.6275e-08 - accuracy: 0.4906 - val_loss: 9.7450e-08 - val_accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 9.6756e-08 - accuracy: 0.4906 - val_loss: 9.3789e-08 - val_accuracy: 0.5000\n",
      "Epoch 00108: early stopping\n",
      "Training model 7 InceptionTime\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 84ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 43ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n",
      "Details of the training process were stored in  .\\models\\modelcomparison.json\n"
     ]
    }
   ],
   "source": [
    "from mcfly.find_architecture import train_models_on_samples\n",
    "\n",
    "outputfile = os.path.join(resultpath, 'modelcomparison.json')\n",
    "histories, val_accuracies, val_losses = train_models_on_samples(train, train_target,\n",
    "                                                                validation, validation_target,\n",
    "                                                                models, nr_epochs=200,\n",
    "                                                                subset_size=300,\n",
    "                                                                early_stopping_patience = 5,\n",
    "                                                                verbose=True,\n",
    "                                                                outputfile=outputfile,\n",
    "                                                                metric=metric)\n",
    "print('Details of the training process were stored in ',outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect model performance (Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model-type</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.005481464347736465, 'regul...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>1.707531e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.612915e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.0394693672382836, 'regular...</td>\n",
       "      <td>ResNet</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.016768945015015333, 'regul...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.013689688066052806, 'regul...</td>\n",
       "      <td>DeepConvLSTM</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>8.884466e-08</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.940697e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.02183138953555479, 'regula...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>1.781881e+00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.865005e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.022294114160952016, 'regul...</td>\n",
       "      <td>ResNet</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 0.005216294589208116, 'regul...</td>\n",
       "      <td>DeepConvLSTM</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>9.675642e-08</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.378899e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 0.00010433835028846764, 'reg...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     model-type  \\\n",
       "0  {'learning_rate': 0.005481464347736465, 'regul...            CNN   \n",
       "1  {'learning_rate': 0.0394693672382836, 'regular...         ResNet   \n",
       "2  {'learning_rate': 0.016768945015015333, 'regul...  InceptionTime   \n",
       "3  {'learning_rate': 0.013689688066052806, 'regul...   DeepConvLSTM   \n",
       "4  {'learning_rate': 0.02183138953555479, 'regula...            CNN   \n",
       "5  {'learning_rate': 0.022294114160952016, 'regul...         ResNet   \n",
       "6  {'learning_rate': 0.005216294589208116, 'regul...   DeepConvLSTM   \n",
       "7  {'learning_rate': 0.00010433835028846764, 'reg...  InceptionTime   \n",
       "\n",
       "   train_accuracy    train_loss  val_accuracy      val_loss  \n",
       "0        0.490566  1.707531e-01           0.5  1.612915e-01  \n",
       "1        0.490566  0.000000e+00           0.5  0.000000e+00  \n",
       "2        0.490566  0.000000e+00           0.5  0.000000e+00  \n",
       "3        0.490566  8.884466e-08           0.5  8.940697e-08  \n",
       "4        0.490566  1.781881e+00           0.5  1.865005e+00  \n",
       "5        0.490566  0.000000e+00           0.5  0.000000e+00  \n",
       "6        0.490566  9.675642e-08           0.5  9.378899e-08  \n",
       "7        0.490566  0.000000e+00           0.5  0.000000e+00  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = 'accuracy'\n",
    "modelcomparisons = pd.DataFrame({'model':[str(params) for model, params, model_types in models],\n",
    "                                'model-type':[str(model_types) for model, params, model_types in models],\n",
    "                                'train_{}'.format(metric): [history.history[metric][-1] for history in histories],\n",
    "                                'train_loss': [history.history['loss'][-1] for history in histories],\n",
    "                                'val_{}'.format(metric): [history.history['val_{}'.format(metric)][-1] for history in histories],\n",
    "                                'val_loss': [history.history['val_loss'][-1] for history in histories]\n",
    "                                })\n",
    "modelcomparisons.to_csv(os.path.join(resultpath, 'modelcomparisons.csv'))\n",
    "\n",
    "modelcomparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Continue iteratively: generate more models of desired type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of low_lr is set from 1 (default) to 2\n",
      "Set maximum kernel size for InceptionTime models to number of timesteps.\n",
      "Set maximum kernel size for InceptionTime models to number of timesteps.\n",
      "Set maximum kernel size for InceptionTime models to number of timesteps.\n",
      "Set maximum kernel size for InceptionTime models to number of timesteps.\n"
     ]
    }
   ],
   "source": [
    "num_classes = train_target.shape[1]\n",
    "metric = 'accuracy'\n",
    "models = mcfly.modelgen.generate_models(train.shape,\n",
    "                                        number_of_classes=num_classes,\n",
    "                                        number_of_models = 8,\n",
    "                                        model_types = ['CNN', 'InceptionTime'],\n",
    "                                        low_lr=2,\n",
    "                                        metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated models will be trained on subset of the data (subset size: 300).\n",
      "Training model 0 CNN\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\mcfly\\find_architecture.py:134: UserWarning: Argument 'metric' is deprecated and will be ignored.\n",
      "  warnings.warn(\"Argument 'metric' is deprecated and will be ignored.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 43ms/step - loss: 1.4560 - accuracy: 0.4906 - val_loss: 1.4105 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.3887 - accuracy: 0.4906 - val_loss: 1.3477 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.3227 - accuracy: 0.4906 - val_loss: 1.2778 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.2517 - accuracy: 0.4906 - val_loss: 1.2057 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 1.1797 - accuracy: 0.4906 - val_loss: 1.1342 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 1.1089 - accuracy: 0.4906 - val_loss: 1.0650 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 1.0408 - accuracy: 0.4906 - val_loss: 0.9989 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9760 - accuracy: 0.4906 - val_loss: 0.9364 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9149 - accuracy: 0.4906 - val_loss: 0.8779 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8578 - accuracy: 0.4906 - val_loss: 0.8232 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8046 - accuracy: 0.4906 - val_loss: 0.7724 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7551 - accuracy: 0.4906 - val_loss: 0.7253 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7092 - accuracy: 0.4906 - val_loss: 0.6816 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6667 - accuracy: 0.4906 - val_loss: 0.6411 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6273 - accuracy: 0.4906 - val_loss: 0.6035 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5907 - accuracy: 0.4906 - val_loss: 0.5687 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5569 - accuracy: 0.4906 - val_loss: 0.5365 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5255 - accuracy: 0.4906 - val_loss: 0.5066 - val_accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4964 - accuracy: 0.4906 - val_loss: 0.4788 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4694 - accuracy: 0.4906 - val_loss: 0.4531 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.4443 - accuracy: 0.4906 - val_loss: 0.4291 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.4210 - accuracy: 0.4906 - val_loss: 0.4069 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3993 - accuracy: 0.4906 - val_loss: 0.3862 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3791 - accuracy: 0.4906 - val_loss: 0.3668 - val_accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3602 - accuracy: 0.4906 - val_loss: 0.3488 - val_accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3427 - accuracy: 0.4906 - val_loss: 0.3320 - val_accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.3263 - accuracy: 0.4906 - val_loss: 0.3163 - val_accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.3109 - accuracy: 0.4906 - val_loss: 0.3017 - val_accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2966 - accuracy: 0.4906 - val_loss: 0.2880 - val_accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.2833 - accuracy: 0.4906 - val_loss: 0.2754 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2712 - accuracy: 0.4906 - val_loss: 0.2638 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2599 - accuracy: 0.4906 - val_loss: 0.2531 - val_accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2493 - accuracy: 0.4906 - val_loss: 0.2429 - val_accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2393 - accuracy: 0.4906 - val_loss: 0.2332 - val_accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.2298 - accuracy: 0.4906 - val_loss: 0.2239 - val_accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2207 - accuracy: 0.4906 - val_loss: 0.2151 - val_accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2120 - accuracy: 0.4906 - val_loss: 0.2068 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.2039 - accuracy: 0.4906 - val_loss: 0.1989 - val_accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1962 - accuracy: 0.4906 - val_loss: 0.1915 - val_accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1889 - accuracy: 0.4906 - val_loss: 0.1844 - val_accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1820 - accuracy: 0.4906 - val_loss: 0.1778 - val_accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1755 - accuracy: 0.4906 - val_loss: 0.1715 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1694 - accuracy: 0.4906 - val_loss: 0.1656 - val_accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1635 - accuracy: 0.4906 - val_loss: 0.1600 - val_accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1580 - accuracy: 0.4906 - val_loss: 0.1547 - val_accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1528 - accuracy: 0.4906 - val_loss: 0.1496 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1479 - accuracy: 0.4906 - val_loss: 0.1451 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1437 - accuracy: 0.4906 - val_loss: 0.1413 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1400 - accuracy: 0.4906 - val_loss: 0.1379 - val_accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.1367 - accuracy: 0.4906 - val_loss: 0.1346 - val_accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1333 - accuracy: 0.4906 - val_loss: 0.1310 - val_accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.1297 - accuracy: 0.4906 - val_loss: 0.1273 - val_accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1260 - accuracy: 0.4906 - val_loss: 0.1236 - val_accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1223 - accuracy: 0.4906 - val_loss: 0.1199 - val_accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1187 - accuracy: 0.4906 - val_loss: 0.1165 - val_accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1152 - accuracy: 0.4906 - val_loss: 0.1131 - val_accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1120 - accuracy: 0.4906 - val_loss: 0.1099 - val_accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1088 - accuracy: 0.4906 - val_loss: 0.1069 - val_accuracy: 0.5000\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1059 - accuracy: 0.4906 - val_loss: 0.1040 - val_accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.1030 - accuracy: 0.4906 - val_loss: 0.1013 - val_accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.1003 - accuracy: 0.4906 - val_loss: 0.0986 - val_accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0977 - accuracy: 0.4906 - val_loss: 0.0961 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0953 - accuracy: 0.4906 - val_loss: 0.0938 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0930 - accuracy: 0.4906 - val_loss: 0.0918 - val_accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0912 - accuracy: 0.4906 - val_loss: 0.0902 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0897 - accuracy: 0.4906 - val_loss: 0.0889 - val_accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0885 - accuracy: 0.4906 - val_loss: 0.0876 - val_accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0871 - accuracy: 0.4906 - val_loss: 0.0860 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0854 - accuracy: 0.4906 - val_loss: 0.0842 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0835 - accuracy: 0.4906 - val_loss: 0.0822 - val_accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0815 - accuracy: 0.4906 - val_loss: 0.0802 - val_accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0795 - accuracy: 0.4906 - val_loss: 0.0782 - val_accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0776 - accuracy: 0.4906 - val_loss: 0.0764 - val_accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0757 - accuracy: 0.4906 - val_loss: 0.0745 - val_accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0739 - accuracy: 0.4906 - val_loss: 0.0728 - val_accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0722 - accuracy: 0.4906 - val_loss: 0.0712 - val_accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0706 - accuracy: 0.4906 - val_loss: 0.0696 - val_accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0690 - accuracy: 0.4906 - val_loss: 0.0681 - val_accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0675 - accuracy: 0.4906 - val_loss: 0.0666 - val_accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0662 - accuracy: 0.4906 - val_loss: 0.0654 - val_accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0650 - accuracy: 0.4906 - val_loss: 0.0644 - val_accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0642 - accuracy: 0.4906 - val_loss: 0.0638 - val_accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0636 - accuracy: 0.4906 - val_loss: 0.0632 - val_accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0629 - accuracy: 0.4906 - val_loss: 0.0623 - val_accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0619 - accuracy: 0.4906 - val_loss: 0.0612 - val_accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0607 - accuracy: 0.4906 - val_loss: 0.0599 - val_accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0595 - accuracy: 0.4906 - val_loss: 0.0586 - val_accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0582 - accuracy: 0.4906 - val_loss: 0.0574 - val_accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0569 - accuracy: 0.4906 - val_loss: 0.0561 - val_accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0557 - accuracy: 0.4906 - val_loss: 0.0549 - val_accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0545 - accuracy: 0.4906 - val_loss: 0.0538 - val_accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0534 - accuracy: 0.4906 - val_loss: 0.0528 - val_accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0524 - accuracy: 0.4906 - val_loss: 0.0518 - val_accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0515 - accuracy: 0.4906 - val_loss: 0.0509 - val_accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0506 - accuracy: 0.4906 - val_loss: 0.0500 - val_accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0497 - accuracy: 0.4906 - val_loss: 0.0492 - val_accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0489 - accuracy: 0.4906 - val_loss: 0.0485 - val_accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0482 - accuracy: 0.4906 - val_loss: 0.0478 - val_accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0475 - accuracy: 0.4906 - val_loss: 0.0470 - val_accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0467 - accuracy: 0.4906 - val_loss: 0.0462 - val_accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0459 - accuracy: 0.4906 - val_loss: 0.0453 - val_accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0450 - accuracy: 0.4906 - val_loss: 0.0444 - val_accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0441 - accuracy: 0.4906 - val_loss: 0.0436 - val_accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0433 - accuracy: 0.4906 - val_loss: 0.0427 - val_accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0424 - accuracy: 0.4906 - val_loss: 0.0419 - val_accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0416 - accuracy: 0.4906 - val_loss: 0.0412 - val_accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0409 - accuracy: 0.4906 - val_loss: 0.0405 - val_accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0403 - accuracy: 0.4906 - val_loss: 0.0399 - val_accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0398 - accuracy: 0.4906 - val_loss: 0.0395 - val_accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0394 - accuracy: 0.4906 - val_loss: 0.0392 - val_accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0391 - accuracy: 0.4906 - val_loss: 0.0388 - val_accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.0387 - accuracy: 0.4906 - val_loss: 0.0383 - val_accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0381 - accuracy: 0.4906 - val_loss: 0.0377 - val_accuracy: 0.5000\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0375 - accuracy: 0.4906 - val_loss: 0.0370 - val_accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0367 - accuracy: 0.4906 - val_loss: 0.0363 - val_accuracy: 0.5000\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0360 - accuracy: 0.4906 - val_loss: 0.0355 - val_accuracy: 0.5000\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0353 - accuracy: 0.4906 - val_loss: 0.0348 - val_accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0346 - accuracy: 0.4906 - val_loss: 0.0342 - val_accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0339 - accuracy: 0.4906 - val_loss: 0.0336 - val_accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0334 - accuracy: 0.4906 - val_loss: 0.0330 - val_accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0329 - accuracy: 0.4906 - val_loss: 0.0326 - val_accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0325 - accuracy: 0.4906 - val_loss: 0.0323 - val_accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0322 - accuracy: 0.4906 - val_loss: 0.0320 - val_accuracy: 0.5000\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0319 - accuracy: 0.4906 - val_loss: 0.0316 - val_accuracy: 0.5000\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0315 - accuracy: 0.4906 - val_loss: 0.0311 - val_accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0309 - accuracy: 0.4906 - val_loss: 0.0306 - val_accuracy: 0.5000\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0304 - accuracy: 0.4906 - val_loss: 0.0300 - val_accuracy: 0.5000\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0298 - accuracy: 0.4906 - val_loss: 0.0294 - val_accuracy: 0.5000\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0292 - accuracy: 0.4906 - val_loss: 0.0289 - val_accuracy: 0.5000\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0287 - accuracy: 0.4906 - val_loss: 0.0283 - val_accuracy: 0.5000\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0281 - accuracy: 0.4906 - val_loss: 0.0278 - val_accuracy: 0.5000\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0276 - accuracy: 0.4906 - val_loss: 0.0274 - val_accuracy: 0.5000\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0272 - accuracy: 0.4906 - val_loss: 0.0270 - val_accuracy: 0.5000\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0269 - accuracy: 0.4906 - val_loss: 0.0267 - val_accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0267 - accuracy: 0.4906 - val_loss: 0.0266 - val_accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0266 - accuracy: 0.4906 - val_loss: 0.0267 - val_accuracy: 0.5000\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0268 - accuracy: 0.4906 - val_loss: 0.0268 - val_accuracy: 0.5000\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0268 - accuracy: 0.4906 - val_loss: 0.0266 - val_accuracy: 0.5000\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0265 - accuracy: 0.4906 - val_loss: 0.0262 - val_accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0260 - accuracy: 0.4906 - val_loss: 0.0257 - val_accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0255 - accuracy: 0.4906 - val_loss: 0.0251 - val_accuracy: 0.5000\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0249 - accuracy: 0.4906 - val_loss: 0.0246 - val_accuracy: 0.5000\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0244 - accuracy: 0.4906 - val_loss: 0.0240 - val_accuracy: 0.5000\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0238 - accuracy: 0.4906 - val_loss: 0.0235 - val_accuracy: 0.5000\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0233 - accuracy: 0.4906 - val_loss: 0.0230 - val_accuracy: 0.5000\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0229 - accuracy: 0.4906 - val_loss: 0.0226 - val_accuracy: 0.5000\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0224 - accuracy: 0.4906 - val_loss: 0.0221 - val_accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0220 - accuracy: 0.4906 - val_loss: 0.0217 - val_accuracy: 0.5000\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0216 - accuracy: 0.4906 - val_loss: 0.0214 - val_accuracy: 0.5000\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0214 - accuracy: 0.4906 - val_loss: 0.0213 - val_accuracy: 0.5000\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0213 - accuracy: 0.4906 - val_loss: 0.0213 - val_accuracy: 0.5000\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0213 - accuracy: 0.4906 - val_loss: 0.0212 - val_accuracy: 0.5000\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.0212 - accuracy: 0.4906 - val_loss: 0.0211 - val_accuracy: 0.5000\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0211 - accuracy: 0.4906 - val_loss: 0.0210 - val_accuracy: 0.5000\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0209 - accuracy: 0.4906 - val_loss: 0.0208 - val_accuracy: 0.5000\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0207 - accuracy: 0.4906 - val_loss: 0.0205 - val_accuracy: 0.5000\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.0203 - accuracy: 0.4906 - val_loss: 0.0201 - val_accuracy: 0.5000\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0199 - accuracy: 0.4906 - val_loss: 0.0196 - val_accuracy: 0.5000\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0195 - accuracy: 0.4906 - val_loss: 0.0192 - val_accuracy: 0.5000\n",
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0190 - accuracy: 0.4906 - val_loss: 0.0188 - val_accuracy: 0.5000\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0186 - accuracy: 0.4906 - val_loss: 0.0184 - val_accuracy: 0.5000\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0183 - accuracy: 0.4906 - val_loss: 0.0180 - val_accuracy: 0.5000\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0179 - accuracy: 0.4906 - val_loss: 0.0177 - val_accuracy: 0.5000\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0175 - accuracy: 0.4906 - val_loss: 0.0173 - val_accuracy: 0.5000\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0172 - accuracy: 0.4906 - val_loss: 0.0170 - val_accuracy: 0.5000\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0170 - accuracy: 0.4906 - val_loss: 0.0169 - val_accuracy: 0.5000\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0169 - accuracy: 0.4906 - val_loss: 0.0170 - val_accuracy: 0.5000\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0172 - accuracy: 0.4906 - val_loss: 0.0174 - val_accuracy: 0.5000\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.0176 - accuracy: 0.4906 - val_loss: 0.0177 - val_accuracy: 0.5000\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.0178 - accuracy: 0.4906 - val_loss: 0.0179 - val_accuracy: 0.5000\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.0179 - accuracy: 0.4906 - val_loss: 0.0178 - val_accuracy: 0.5000\n",
      "Epoch 00171: early stopping\n",
      "Training model 1 InceptionTime\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 169ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 1s 102ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 107ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 1s 103ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 1s 98ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n",
      "Training model 2 CNN\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 45ms/step - loss: 4.1396 - accuracy: 0.4906 - val_loss: 3.9063 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.7739 - accuracy: 0.4906 - val_loss: 3.5385 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 3.4049 - accuracy: 0.4906 - val_loss: 3.1705 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 3.0414 - accuracy: 0.4906 - val_loss: 2.8192 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 2.7001 - accuracy: 0.4906 - val_loss: 2.4976 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 2.3910 - accuracy: 0.4906 - val_loss: 2.2110 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 2.1174 - accuracy: 0.4906 - val_loss: 1.9601 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 1.8790 - accuracy: 0.4906 - val_loss: 1.7433 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.6737 - accuracy: 0.4906 - val_loss: 1.5574 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.4980 - accuracy: 0.4906 - val_loss: 1.3989 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.3483 - accuracy: 0.4906 - val_loss: 1.2641 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 1.2212 - accuracy: 0.4906 - val_loss: 1.1497 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 1.1134 - accuracy: 0.4906 - val_loss: 1.0537 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 1.0235 - accuracy: 0.4906 - val_loss: 0.9735 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.9480 - accuracy: 0.4906 - val_loss: 0.9053 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.8832 - accuracy: 0.4906 - val_loss: 0.8462 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.8269 - accuracy: 0.4906 - val_loss: 0.7946 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.7779 - accuracy: 0.4906 - val_loss: 0.7498 - val_accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.7352 - accuracy: 0.4906 - val_loss: 0.7106 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.6979 - accuracy: 0.4906 - val_loss: 0.6765 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.6655 - accuracy: 0.4906 - val_loss: 0.6468 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6371 - accuracy: 0.4906 - val_loss: 0.6207 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.6120 - accuracy: 0.4906 - val_loss: 0.5973 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5896 - accuracy: 0.4906 - val_loss: 0.5765 - val_accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.5697 - accuracy: 0.4906 - val_loss: 0.5581 - val_accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5520 - accuracy: 0.4906 - val_loss: 0.5415 - val_accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5359 - accuracy: 0.4906 - val_loss: 0.5263 - val_accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5211 - accuracy: 0.4906 - val_loss: 0.5121 - val_accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.5072 - accuracy: 0.4906 - val_loss: 0.4988 - val_accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4942 - accuracy: 0.4906 - val_loss: 0.4863 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4821 - accuracy: 0.4906 - val_loss: 0.4748 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.4709 - accuracy: 0.4906 - val_loss: 0.4644 - val_accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4612 - accuracy: 0.4906 - val_loss: 0.4560 - val_accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.4532 - accuracy: 0.4906 - val_loss: 0.4483 - val_accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.4454 - accuracy: 0.4906 - val_loss: 0.4402 - val_accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.4371 - accuracy: 0.4906 - val_loss: 0.4316 - val_accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4284 - accuracy: 0.4906 - val_loss: 0.4229 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4199 - accuracy: 0.4906 - val_loss: 0.4145 - val_accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.4116 - accuracy: 0.4906 - val_loss: 0.4066 - val_accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.4039 - accuracy: 0.4906 - val_loss: 0.3995 - val_accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3974 - accuracy: 0.4906 - val_loss: 0.3943 - val_accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3930 - accuracy: 0.4906 - val_loss: 0.3909 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3904 - accuracy: 0.4906 - val_loss: 0.3894 - val_accuracy: 0.5000\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3883 - accuracy: 0.4906 - val_loss: 0.3861 - val_accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3844 - accuracy: 0.4906 - val_loss: 0.3811 - val_accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3789 - accuracy: 0.4906 - val_loss: 0.3746 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3719 - accuracy: 0.4906 - val_loss: 0.3671 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3644 - accuracy: 0.4906 - val_loss: 0.3597 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3571 - accuracy: 0.4906 - val_loss: 0.3526 - val_accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3501 - accuracy: 0.4906 - val_loss: 0.3458 - val_accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3435 - accuracy: 0.4906 - val_loss: 0.3395 - val_accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3373 - accuracy: 0.4906 - val_loss: 0.3336 - val_accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.3316 - accuracy: 0.4906 - val_loss: 0.3283 - val_accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3265 - accuracy: 0.4906 - val_loss: 0.3238 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3225 - accuracy: 0.4906 - val_loss: 0.3206 - val_accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3198 - accuracy: 0.4906 - val_loss: 0.3183 - val_accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3180 - accuracy: 0.4906 - val_loss: 0.3172 - val_accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3163 - accuracy: 0.4906 - val_loss: 0.3146 - val_accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.3134 - accuracy: 0.4906 - val_loss: 0.3108 - val_accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.3090 - accuracy: 0.4906 - val_loss: 0.3057 - val_accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.3037 - accuracy: 0.4906 - val_loss: 0.3001 - val_accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2980 - accuracy: 0.4906 - val_loss: 0.2944 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2924 - accuracy: 0.4906 - val_loss: 0.2889 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2870 - accuracy: 0.4906 - val_loss: 0.2837 - val_accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.2820 - accuracy: 0.4906 - val_loss: 0.2790 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.2774 - accuracy: 0.4906 - val_loss: 0.2747 - val_accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2734 - accuracy: 0.4906 - val_loss: 0.2713 - val_accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2704 - accuracy: 0.4906 - val_loss: 0.2694 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2699 - accuracy: 0.4906 - val_loss: 0.2713 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2718 - accuracy: 0.4906 - val_loss: 0.2722 - val_accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2717 - accuracy: 0.4906 - val_loss: 0.2700 - val_accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2685 - accuracy: 0.4906 - val_loss: 0.2655 - val_accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2635 - accuracy: 0.4906 - val_loss: 0.2600 - val_accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2579 - accuracy: 0.4906 - val_loss: 0.2543 - val_accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.2523 - accuracy: 0.4906 - val_loss: 0.2488 - val_accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2469 - accuracy: 0.4906 - val_loss: 0.2437 - val_accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2420 - accuracy: 0.4906 - val_loss: 0.2390 - val_accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2375 - accuracy: 0.4906 - val_loss: 0.2348 - val_accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2335 - accuracy: 0.4906 - val_loss: 0.2314 - val_accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2304 - accuracy: 0.4906 - val_loss: 0.2295 - val_accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2293 - accuracy: 0.4906 - val_loss: 0.2289 - val_accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2294 - accuracy: 0.4906 - val_loss: 0.2303 - val_accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2302 - accuracy: 0.4906 - val_loss: 0.2298 - val_accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2291 - accuracy: 0.4906 - val_loss: 0.2275 - val_accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2262 - accuracy: 0.4906 - val_loss: 0.2235 - val_accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2218 - accuracy: 0.4906 - val_loss: 0.2186 - val_accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2168 - accuracy: 0.4906 - val_loss: 0.2136 - val_accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2119 - accuracy: 0.4906 - val_loss: 0.2089 - val_accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.2073 - accuracy: 0.4906 - val_loss: 0.2045 - val_accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.2030 - accuracy: 0.4906 - val_loss: 0.2004 - val_accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1991 - accuracy: 0.4906 - val_loss: 0.1967 - val_accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1955 - accuracy: 0.4906 - val_loss: 0.1934 - val_accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1924 - accuracy: 0.4906 - val_loss: 0.1907 - val_accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1899 - accuracy: 0.4906 - val_loss: 0.1890 - val_accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1888 - accuracy: 0.4906 - val_loss: 0.1884 - val_accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.1886 - accuracy: 0.4906 - val_loss: 0.1889 - val_accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1887 - accuracy: 0.4906 - val_loss: 0.1881 - val_accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1874 - accuracy: 0.4906 - val_loss: 0.1859 - val_accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1847 - accuracy: 0.4906 - val_loss: 0.1825 - val_accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1811 - accuracy: 0.4906 - val_loss: 0.1786 - val_accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1772 - accuracy: 0.4906 - val_loss: 0.1747 - val_accuracy: 0.5000\n",
      "Epoch 102/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.1734 - accuracy: 0.4906 - val_loss: 0.1710 - val_accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1697 - accuracy: 0.4906 - val_loss: 0.1675 - val_accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1664 - accuracy: 0.4906 - val_loss: 0.1644 - val_accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1634 - accuracy: 0.4906 - val_loss: 0.1616 - val_accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1606 - accuracy: 0.4906 - val_loss: 0.1591 - val_accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1582 - accuracy: 0.4906 - val_loss: 0.1567 - val_accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1560 - accuracy: 0.4906 - val_loss: 0.1551 - val_accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 25ms/step - loss: 0.1550 - accuracy: 0.4906 - val_loss: 0.1554 - val_accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1567 - accuracy: 0.4906 - val_loss: 0.1593 - val_accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1603 - accuracy: 0.4906 - val_loss: 0.1614 - val_accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.1612 - accuracy: 0.4906 - val_loss: 0.1602 - val_accuracy: 0.5000\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 24ms/step - loss: 0.1591 - accuracy: 0.4906 - val_loss: 0.1568 - val_accuracy: 0.5000\n",
      "Epoch 00113: early stopping\n",
      "Training model 3 InceptionTime\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 196ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 1s 136ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 1s 122ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 1s 115ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n",
      "Training model 4 InceptionTime\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 156ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 1s 117ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 1s 119ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 1s 109ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 1s 118ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n",
      "Training model 5 CNN\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 49ms/step - loss: 0.1920 - accuracy: 0.4906 - val_loss: 0.1899 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1893 - accuracy: 0.4906 - val_loss: 0.1881 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1873 - accuracy: 0.4906 - val_loss: 0.1859 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1850 - accuracy: 0.4906 - val_loss: 0.1835 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.1825 - accuracy: 0.4906 - val_loss: 0.1808 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1798 - accuracy: 0.4906 - val_loss: 0.1781 - val_accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1771 - accuracy: 0.4906 - val_loss: 0.1753 - val_accuracy: 0.5000\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1742 - accuracy: 0.4906 - val_loss: 0.1724 - val_accuracy: 0.5000\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1714 - accuracy: 0.4906 - val_loss: 0.1697 - val_accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.1687 - accuracy: 0.4906 - val_loss: 0.1669 - val_accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1659 - accuracy: 0.4906 - val_loss: 0.1642 - val_accuracy: 0.5000\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 0.1633 - accuracy: 0.4906 - val_loss: 0.1616 - val_accuracy: 0.5000\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1606 - accuracy: 0.4906 - val_loss: 0.1590 - val_accuracy: 0.5000\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1581 - accuracy: 0.4906 - val_loss: 0.1565 - val_accuracy: 0.5000\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1555 - accuracy: 0.4906 - val_loss: 0.1539 - val_accuracy: 0.5000\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1531 - accuracy: 0.4906 - val_loss: 0.1515 - val_accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1506 - accuracy: 0.4906 - val_loss: 0.1491 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1482 - accuracy: 0.4906 - val_loss: 0.1467 - val_accuracy: 0.5000\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1458 - accuracy: 0.4906 - val_loss: 0.1443 - val_accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1435 - accuracy: 0.4906 - val_loss: 0.1420 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1412 - accuracy: 0.4906 - val_loss: 0.1398 - val_accuracy: 0.5000\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1390 - accuracy: 0.4906 - val_loss: 0.1375 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1368 - accuracy: 0.4906 - val_loss: 0.1354 - val_accuracy: 0.5000\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1346 - accuracy: 0.4906 - val_loss: 0.1332 - val_accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1325 - accuracy: 0.4906 - val_loss: 0.1311 - val_accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1304 - accuracy: 0.4906 - val_loss: 0.1291 - val_accuracy: 0.5000\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1284 - accuracy: 0.4906 - val_loss: 0.1271 - val_accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.1264 - accuracy: 0.4906 - val_loss: 0.1251 - val_accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1244 - accuracy: 0.4906 - val_loss: 0.1232 - val_accuracy: 0.5000\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1225 - accuracy: 0.4906 - val_loss: 0.1213 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1206 - accuracy: 0.4906 - val_loss: 0.1194 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1187 - accuracy: 0.4906 - val_loss: 0.1175 - val_accuracy: 0.5000\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1169 - accuracy: 0.4906 - val_loss: 0.1157 - val_accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1151 - accuracy: 0.4906 - val_loss: 0.1140 - val_accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1134 - accuracy: 0.4906 - val_loss: 0.1122 - val_accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1116 - accuracy: 0.4906 - val_loss: 0.1105 - val_accuracy: 0.5000\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.1099 - accuracy: 0.4906 - val_loss: 0.1089 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.1083 - accuracy: 0.4906 - val_loss: 0.1072 - val_accuracy: 0.5000\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1066 - accuracy: 0.4906 - val_loss: 0.1056 - val_accuracy: 0.5000\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.1050 - accuracy: 0.4906 - val_loss: 0.1040 - val_accuracy: 0.5000\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.1035 - accuracy: 0.4906 - val_loss: 0.1025 - val_accuracy: 0.5000\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.1020 - accuracy: 0.4906 - val_loss: 0.1010 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.1005 - accuracy: 0.4906 - val_loss: 0.0996 - val_accuracy: 0.5000\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0990 - accuracy: 0.4906 - val_loss: 0.0981 - val_accuracy: 0.5000\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0976 - accuracy: 0.4906 - val_loss: 0.0967 - val_accuracy: 0.5000\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0961 - accuracy: 0.4906 - val_loss: 0.0952 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 0.0947 - accuracy: 0.4906 - val_loss: 0.0938 - val_accuracy: 0.5000\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.0933 - accuracy: 0.4906 - val_loss: 0.0925 - val_accuracy: 0.5000\n",
      "Epoch 49/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0920 - accuracy: 0.4906 - val_loss: 0.0911 - val_accuracy: 0.5000\n",
      "Epoch 50/200\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.0906 - accuracy: 0.4906 - val_loss: 0.0898 - val_accuracy: 0.5000\n",
      "Epoch 51/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0893 - accuracy: 0.4906 - val_loss: 0.0885 - val_accuracy: 0.5000\n",
      "Epoch 52/200\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.0880 - accuracy: 0.4906 - val_loss: 0.0872 - val_accuracy: 0.5000\n",
      "Epoch 53/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0867 - accuracy: 0.4906 - val_loss: 0.0859 - val_accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0854 - accuracy: 0.4906 - val_loss: 0.0847 - val_accuracy: 0.5000\n",
      "Epoch 55/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0842 - accuracy: 0.4906 - val_loss: 0.0834 - val_accuracy: 0.5000\n",
      "Epoch 56/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0830 - accuracy: 0.4906 - val_loss: 0.0822 - val_accuracy: 0.5000\n",
      "Epoch 57/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0818 - accuracy: 0.4906 - val_loss: 0.0810 - val_accuracy: 0.5000\n",
      "Epoch 58/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0806 - accuracy: 0.4906 - val_loss: 0.0799 - val_accuracy: 0.5000\n",
      "Epoch 59/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0795 - accuracy: 0.4906 - val_loss: 0.0787 - val_accuracy: 0.5000\n",
      "Epoch 60/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0783 - accuracy: 0.4906 - val_loss: 0.0776 - val_accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0772 - accuracy: 0.4906 - val_loss: 0.0765 - val_accuracy: 0.5000\n",
      "Epoch 62/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0761 - accuracy: 0.4906 - val_loss: 0.0755 - val_accuracy: 0.5000\n",
      "Epoch 63/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0751 - accuracy: 0.4906 - val_loss: 0.0744 - val_accuracy: 0.5000\n",
      "Epoch 64/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0741 - accuracy: 0.4906 - val_loss: 0.0735 - val_accuracy: 0.5000\n",
      "Epoch 65/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0731 - accuracy: 0.4906 - val_loss: 0.0725 - val_accuracy: 0.5000\n",
      "Epoch 66/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0722 - accuracy: 0.4906 - val_loss: 0.0716 - val_accuracy: 0.5000\n",
      "Epoch 67/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0712 - accuracy: 0.4906 - val_loss: 0.0706 - val_accuracy: 0.5000\n",
      "Epoch 68/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0703 - accuracy: 0.4906 - val_loss: 0.0696 - val_accuracy: 0.5000\n",
      "Epoch 69/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0693 - accuracy: 0.4906 - val_loss: 0.0687 - val_accuracy: 0.5000\n",
      "Epoch 70/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0683 - accuracy: 0.4906 - val_loss: 0.0677 - val_accuracy: 0.5000\n",
      "Epoch 71/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0674 - accuracy: 0.4906 - val_loss: 0.0668 - val_accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0664 - accuracy: 0.4906 - val_loss: 0.0658 - val_accuracy: 0.5000\n",
      "Epoch 73/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0655 - accuracy: 0.4906 - val_loss: 0.0649 - val_accuracy: 0.5000\n",
      "Epoch 74/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0646 - accuracy: 0.4906 - val_loss: 0.0640 - val_accuracy: 0.5000\n",
      "Epoch 75/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0637 - accuracy: 0.4906 - val_loss: 0.0631 - val_accuracy: 0.5000\n",
      "Epoch 76/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0628 - accuracy: 0.4906 - val_loss: 0.0623 - val_accuracy: 0.5000\n",
      "Epoch 77/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0620 - accuracy: 0.4906 - val_loss: 0.0614 - val_accuracy: 0.5000\n",
      "Epoch 78/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0611 - accuracy: 0.4906 - val_loss: 0.0606 - val_accuracy: 0.5000\n",
      "Epoch 79/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0603 - accuracy: 0.4906 - val_loss: 0.0598 - val_accuracy: 0.5000\n",
      "Epoch 80/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0595 - accuracy: 0.4906 - val_loss: 0.0589 - val_accuracy: 0.5000\n",
      "Epoch 81/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0586 - accuracy: 0.4906 - val_loss: 0.0581 - val_accuracy: 0.5000\n",
      "Epoch 82/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0578 - accuracy: 0.4906 - val_loss: 0.0573 - val_accuracy: 0.5000\n",
      "Epoch 83/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0571 - accuracy: 0.4906 - val_loss: 0.0566 - val_accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0563 - accuracy: 0.4906 - val_loss: 0.0558 - val_accuracy: 0.5000\n",
      "Epoch 85/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0555 - accuracy: 0.4906 - val_loss: 0.0551 - val_accuracy: 0.5000\n",
      "Epoch 86/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0548 - accuracy: 0.4906 - val_loss: 0.0543 - val_accuracy: 0.5000\n",
      "Epoch 87/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0541 - accuracy: 0.4906 - val_loss: 0.0536 - val_accuracy: 0.5000\n",
      "Epoch 88/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0533 - accuracy: 0.4906 - val_loss: 0.0529 - val_accuracy: 0.5000\n",
      "Epoch 89/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0526 - accuracy: 0.4906 - val_loss: 0.0522 - val_accuracy: 0.5000\n",
      "Epoch 90/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0519 - accuracy: 0.4906 - val_loss: 0.0515 - val_accuracy: 0.5000\n",
      "Epoch 91/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0513 - accuracy: 0.4906 - val_loss: 0.0508 - val_accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0506 - accuracy: 0.4906 - val_loss: 0.0502 - val_accuracy: 0.5000\n",
      "Epoch 93/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0500 - accuracy: 0.4906 - val_loss: 0.0497 - val_accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0495 - accuracy: 0.4906 - val_loss: 0.0492 - val_accuracy: 0.5000\n",
      "Epoch 95/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0490 - accuracy: 0.4906 - val_loss: 0.0487 - val_accuracy: 0.5000\n",
      "Epoch 96/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0485 - accuracy: 0.4906 - val_loss: 0.0481 - val_accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0479 - accuracy: 0.4906 - val_loss: 0.0475 - val_accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0473 - accuracy: 0.4906 - val_loss: 0.0469 - val_accuracy: 0.5000\n",
      "Epoch 99/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0467 - accuracy: 0.4906 - val_loss: 0.0463 - val_accuracy: 0.5000\n",
      "Epoch 100/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0461 - accuracy: 0.4906 - val_loss: 0.0457 - val_accuracy: 0.5000\n",
      "Epoch 101/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0455 - accuracy: 0.4906 - val_loss: 0.0451 - val_accuracy: 0.5000\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0449 - accuracy: 0.4906 - val_loss: 0.0445 - val_accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0443 - accuracy: 0.4906 - val_loss: 0.0439 - val_accuracy: 0.5000\n",
      "Epoch 104/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0437 - accuracy: 0.4906 - val_loss: 0.0433 - val_accuracy: 0.5000\n",
      "Epoch 105/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0431 - accuracy: 0.4906 - val_loss: 0.0428 - val_accuracy: 0.5000\n",
      "Epoch 106/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0425 - accuracy: 0.4906 - val_loss: 0.0422 - val_accuracy: 0.5000\n",
      "Epoch 107/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0420 - accuracy: 0.4906 - val_loss: 0.0416 - val_accuracy: 0.5000\n",
      "Epoch 108/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0414 - accuracy: 0.4906 - val_loss: 0.0411 - val_accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0409 - accuracy: 0.4906 - val_loss: 0.0406 - val_accuracy: 0.5000\n",
      "Epoch 110/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0404 - accuracy: 0.4906 - val_loss: 0.0400 - val_accuracy: 0.5000\n",
      "Epoch 111/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0399 - accuracy: 0.4906 - val_loss: 0.0395 - val_accuracy: 0.5000\n",
      "Epoch 112/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0393 - accuracy: 0.4906 - val_loss: 0.0390 - val_accuracy: 0.5000\n",
      "Epoch 113/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0388 - accuracy: 0.4906 - val_loss: 0.0385 - val_accuracy: 0.5000\n",
      "Epoch 114/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0383 - accuracy: 0.4906 - val_loss: 0.0380 - val_accuracy: 0.5000\n",
      "Epoch 115/200\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.0379 - accuracy: 0.4906 - val_loss: 0.0376 - val_accuracy: 0.5000\n",
      "Epoch 116/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0374 - accuracy: 0.4906 - val_loss: 0.0371 - val_accuracy: 0.5000\n",
      "Epoch 117/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0369 - accuracy: 0.4906 - val_loss: 0.0366 - val_accuracy: 0.5000\n",
      "Epoch 118/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0364 - accuracy: 0.4906 - val_loss: 0.0361 - val_accuracy: 0.5000\n",
      "Epoch 119/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0360 - accuracy: 0.4906 - val_loss: 0.0357 - val_accuracy: 0.5000\n",
      "Epoch 120/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0355 - accuracy: 0.4906 - val_loss: 0.0352 - val_accuracy: 0.5000\n",
      "Epoch 121/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0351 - accuracy: 0.4906 - val_loss: 0.0348 - val_accuracy: 0.5000\n",
      "Epoch 122/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0346 - accuracy: 0.4906 - val_loss: 0.0344 - val_accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0342 - accuracy: 0.4906 - val_loss: 0.0339 - val_accuracy: 0.5000\n",
      "Epoch 124/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0338 - accuracy: 0.4906 - val_loss: 0.0335 - val_accuracy: 0.5000\n",
      "Epoch 125/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0334 - accuracy: 0.4906 - val_loss: 0.0331 - val_accuracy: 0.5000\n",
      "Epoch 126/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0330 - accuracy: 0.4906 - val_loss: 0.0327 - val_accuracy: 0.5000\n",
      "Epoch 127/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0326 - accuracy: 0.4906 - val_loss: 0.0323 - val_accuracy: 0.5000\n",
      "Epoch 128/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0322 - accuracy: 0.4906 - val_loss: 0.0319 - val_accuracy: 0.5000\n",
      "Epoch 129/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0318 - accuracy: 0.4906 - val_loss: 0.0317 - val_accuracy: 0.5000\n",
      "Epoch 130/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0316 - accuracy: 0.4906 - val_loss: 0.0314 - val_accuracy: 0.5000\n",
      "Epoch 131/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0314 - accuracy: 0.4906 - val_loss: 0.0313 - val_accuracy: 0.5000\n",
      "Epoch 132/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0313 - accuracy: 0.4906 - val_loss: 0.0313 - val_accuracy: 0.5000\n",
      "Epoch 133/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0313 - accuracy: 0.4906 - val_loss: 0.0313 - val_accuracy: 0.5000\n",
      "Epoch 134/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0312 - accuracy: 0.4906 - val_loss: 0.0311 - val_accuracy: 0.5000\n",
      "Epoch 135/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0311 - accuracy: 0.4906 - val_loss: 0.0309 - val_accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0308 - accuracy: 0.4906 - val_loss: 0.0306 - val_accuracy: 0.5000\n",
      "Epoch 137/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0304 - accuracy: 0.4906 - val_loss: 0.0302 - val_accuracy: 0.5000\n",
      "Epoch 138/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0300 - accuracy: 0.4906 - val_loss: 0.0298 - val_accuracy: 0.5000\n",
      "Epoch 139/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0296 - accuracy: 0.4906 - val_loss: 0.0294 - val_accuracy: 0.5000\n",
      "Epoch 140/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0292 - accuracy: 0.4906 - val_loss: 0.0290 - val_accuracy: 0.5000\n",
      "Epoch 141/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0289 - accuracy: 0.4906 - val_loss: 0.0286 - val_accuracy: 0.5000\n",
      "Epoch 142/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0285 - accuracy: 0.4906 - val_loss: 0.0282 - val_accuracy: 0.5000\n",
      "Epoch 143/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0281 - accuracy: 0.4906 - val_loss: 0.0279 - val_accuracy: 0.5000\n",
      "Epoch 144/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0277 - accuracy: 0.4906 - val_loss: 0.0275 - val_accuracy: 0.5000\n",
      "Epoch 145/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0274 - accuracy: 0.4906 - val_loss: 0.0271 - val_accuracy: 0.5000\n",
      "Epoch 146/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0270 - accuracy: 0.4906 - val_loss: 0.0268 - val_accuracy: 0.5000\n",
      "Epoch 147/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0267 - accuracy: 0.4906 - val_loss: 0.0264 - val_accuracy: 0.5000\n",
      "Epoch 148/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0263 - accuracy: 0.4906 - val_loss: 0.0261 - val_accuracy: 0.5000\n",
      "Epoch 149/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0260 - accuracy: 0.4906 - val_loss: 0.0258 - val_accuracy: 0.5000\n",
      "Epoch 150/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0257 - accuracy: 0.4906 - val_loss: 0.0254 - val_accuracy: 0.5000\n",
      "Epoch 151/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0253 - accuracy: 0.4906 - val_loss: 0.0251 - val_accuracy: 0.5000\n",
      "Epoch 152/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0250 - accuracy: 0.4906 - val_loss: 0.0248 - val_accuracy: 0.5000\n",
      "Epoch 153/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0247 - accuracy: 0.4906 - val_loss: 0.0245 - val_accuracy: 0.5000\n",
      "Epoch 154/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0244 - accuracy: 0.4906 - val_loss: 0.0242 - val_accuracy: 0.5000\n",
      "Epoch 155/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0241 - accuracy: 0.4906 - val_loss: 0.0239 - val_accuracy: 0.5000\n",
      "Epoch 156/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0238 - accuracy: 0.4906 - val_loss: 0.0236 - val_accuracy: 0.5000\n",
      "Epoch 157/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0235 - accuracy: 0.4906 - val_loss: 0.0233 - val_accuracy: 0.5000\n",
      "Epoch 158/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0232 - accuracy: 0.4906 - val_loss: 0.0231 - val_accuracy: 0.5000\n",
      "Epoch 159/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0230 - accuracy: 0.4906 - val_loss: 0.0228 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 160/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0227 - accuracy: 0.4906 - val_loss: 0.0225 - val_accuracy: 0.5000\n",
      "Epoch 161/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0224 - accuracy: 0.4906 - val_loss: 0.0222 - val_accuracy: 0.5000\n",
      "Epoch 162/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0221 - accuracy: 0.4906 - val_loss: 0.0220 - val_accuracy: 0.5000\n",
      "Epoch 163/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0219 - accuracy: 0.4906 - val_loss: 0.0217 - val_accuracy: 0.5000\n",
      "Epoch 164/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0216 - accuracy: 0.4906 - val_loss: 0.0214 - val_accuracy: 0.5000\n",
      "Epoch 165/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0214 - accuracy: 0.4906 - val_loss: 0.0212 - val_accuracy: 0.5000\n",
      "Epoch 166/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0211 - accuracy: 0.4906 - val_loss: 0.0209 - val_accuracy: 0.5000\n",
      "Epoch 167/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0209 - accuracy: 0.4906 - val_loss: 0.0207 - val_accuracy: 0.5000\n",
      "Epoch 168/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0206 - accuracy: 0.4906 - val_loss: 0.0205 - val_accuracy: 0.5000\n",
      "Epoch 169/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0204 - accuracy: 0.4906 - val_loss: 0.0202 - val_accuracy: 0.5000\n",
      "Epoch 170/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0201 - accuracy: 0.4906 - val_loss: 0.0200 - val_accuracy: 0.5000\n",
      "Epoch 171/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0199 - accuracy: 0.4906 - val_loss: 0.0198 - val_accuracy: 0.5000\n",
      "Epoch 172/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0197 - accuracy: 0.4906 - val_loss: 0.0195 - val_accuracy: 0.5000\n",
      "Epoch 173/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0194 - accuracy: 0.4906 - val_loss: 0.0193 - val_accuracy: 0.5000\n",
      "Epoch 174/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0192 - accuracy: 0.4906 - val_loss: 0.0191 - val_accuracy: 0.5000\n",
      "Epoch 175/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0190 - accuracy: 0.4906 - val_loss: 0.0189 - val_accuracy: 0.5000\n",
      "Epoch 176/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0188 - accuracy: 0.4906 - val_loss: 0.0187 - val_accuracy: 0.5000\n",
      "Epoch 177/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0186 - accuracy: 0.4906 - val_loss: 0.0184 - val_accuracy: 0.5000\n",
      "Epoch 178/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0184 - accuracy: 0.4906 - val_loss: 0.0183 - val_accuracy: 0.5000\n",
      "Epoch 179/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0182 - accuracy: 0.4906 - val_loss: 0.0181 - val_accuracy: 0.5000\n",
      "Epoch 180/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0180 - accuracy: 0.4906 - val_loss: 0.0180 - val_accuracy: 0.5000\n",
      "Epoch 181/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0180 - accuracy: 0.4906 - val_loss: 0.0179 - val_accuracy: 0.5000\n",
      "Epoch 182/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0179 - accuracy: 0.4906 - val_loss: 0.0179 - val_accuracy: 0.5000\n",
      "Epoch 183/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0179 - accuracy: 0.4906 - val_loss: 0.0178 - val_accuracy: 0.5000\n",
      "Epoch 184/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0178 - accuracy: 0.4906 - val_loss: 0.0177 - val_accuracy: 0.5000\n",
      "Epoch 185/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0176 - accuracy: 0.4906 - val_loss: 0.0175 - val_accuracy: 0.5000\n",
      "Epoch 186/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0174 - accuracy: 0.4906 - val_loss: 0.0173 - val_accuracy: 0.5000\n",
      "Epoch 187/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0172 - accuracy: 0.4906 - val_loss: 0.0171 - val_accuracy: 0.5000\n",
      "Epoch 188/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0170 - accuracy: 0.4906 - val_loss: 0.0169 - val_accuracy: 0.5000\n",
      "Epoch 189/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0168 - accuracy: 0.4906 - val_loss: 0.0167 - val_accuracy: 0.5000\n",
      "Epoch 190/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0166 - accuracy: 0.4906 - val_loss: 0.0165 - val_accuracy: 0.5000\n",
      "Epoch 191/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0164 - accuracy: 0.4906 - val_loss: 0.0163 - val_accuracy: 0.5000\n",
      "Epoch 192/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0162 - accuracy: 0.4906 - val_loss: 0.0161 - val_accuracy: 0.5000\n",
      "Epoch 193/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0160 - accuracy: 0.4906 - val_loss: 0.0159 - val_accuracy: 0.5000\n",
      "Epoch 194/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0158 - accuracy: 0.4906 - val_loss: 0.0157 - val_accuracy: 0.5000\n",
      "Epoch 195/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0157 - accuracy: 0.4906 - val_loss: 0.0155 - val_accuracy: 0.5000\n",
      "Epoch 196/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0155 - accuracy: 0.4906 - val_loss: 0.0154 - val_accuracy: 0.5000\n",
      "Epoch 197/200\n",
      "6/6 [==============================] - 0s 26ms/step - loss: 0.0153 - accuracy: 0.4906 - val_loss: 0.0152 - val_accuracy: 0.5000\n",
      "Epoch 198/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0151 - accuracy: 0.4906 - val_loss: 0.0150 - val_accuracy: 0.5000\n",
      "Epoch 199/200\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.0149 - accuracy: 0.4906 - val_loss: 0.0148 - val_accuracy: 0.5000\n",
      "Epoch 200/200\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.0148 - accuracy: 0.4906 - val_loss: 0.0147 - val_accuracy: 0.5000\n",
      "Training model 6 CNN\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 61ms/step - loss: 0.1322 - accuracy: 0.4906 - val_loss: 0.1806 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2184 - accuracy: 0.4906 - val_loss: 0.2756 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.2975 - accuracy: 0.4906 - val_loss: 0.3268 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3354 - accuracy: 0.4906 - val_loss: 0.3447 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.3450 - accuracy: 0.4906 - val_loss: 0.3422 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 37ms/step - loss: 0.3381 - accuracy: 0.4906 - val_loss: 0.3294 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n",
      "Training model 7 InceptionTime\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 112ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 46ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 47ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 48ms/step - loss: 0.0000e+00 - accuracy: 0.4906 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "outputfile = os.path.join(resultpath, 'modelcomparison_2.json')\n",
    "histories, val_accuracies, val_losses = train_models_on_samples(train, train_target,\n",
    "                                                                validation, validation_target,\n",
    "                                                                models, nr_epochs=200,\n",
    "                                                                subset_size=300,\n",
    "                                                                early_stopping_patience = 5,\n",
    "                                                                verbose=True,\n",
    "                                                                outputfile=outputfile,\n",
    "                                                                metric=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>model-type</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'learning_rate': 0.00037806416493937304, 'reg...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.017885</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.017807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'learning_rate': 0.0007123853990530968, 'regu...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'learning_rate': 0.00034914273335304115, 'reg...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.159114</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.156823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'learning_rate': 0.008889925393993863, 'regul...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'learning_rate': 0.00022246617439914524, 'reg...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'learning_rate': 0.0005081261465795578, 'regu...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.014766</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.014659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'learning_rate': 0.0045608494108193166, 'regu...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.338133</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.329399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'learning_rate': 0.0014378820648315474, 'regu...</td>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model     model-type  \\\n",
       "0  {'learning_rate': 0.00037806416493937304, 'reg...            CNN   \n",
       "1  {'learning_rate': 0.0007123853990530968, 'regu...  InceptionTime   \n",
       "2  {'learning_rate': 0.00034914273335304115, 'reg...            CNN   \n",
       "3  {'learning_rate': 0.008889925393993863, 'regul...  InceptionTime   \n",
       "4  {'learning_rate': 0.00022246617439914524, 'reg...  InceptionTime   \n",
       "5  {'learning_rate': 0.0005081261465795578, 'regu...            CNN   \n",
       "6  {'learning_rate': 0.0045608494108193166, 'regu...            CNN   \n",
       "7  {'learning_rate': 0.0014378820648315474, 'regu...  InceptionTime   \n",
       "\n",
       "   train_accuracy  train_loss  val_accuracy  val_loss  \n",
       "0        0.490566    0.017885           0.5  0.017807  \n",
       "1        0.490566    0.000000           0.5  0.000000  \n",
       "2        0.490566    0.159114           0.5  0.156823  \n",
       "3        0.490566    0.000000           0.5  0.000000  \n",
       "4        0.490566    0.000000           0.5  0.000000  \n",
       "5        0.490566    0.014766           0.5  0.014659  \n",
       "6        0.490566    0.338133           0.5  0.329399  \n",
       "7        0.490566    0.000000           0.5  0.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric = 'accuracy'\n",
    "modelcomparisons_2 = pd.DataFrame({'model':[str(params) for model, params, model_types in models],\n",
    "                                'model-type':[str(model_types) for model, params, model_types in models],\n",
    "                                'train_{}'.format(metric): [history.history[metric][-1] for history in histories],\n",
    "                                'train_loss': [history.history['loss'][-1] for history in histories],\n",
    "                                'val_{}'.format(metric): [history.history['val_{}'.format(metric)][-1] for history in histories],\n",
    "                                'val_loss': [history.history['val_loss'][-1] for history in histories]\n",
    "                                })\n",
    "modelcomparisons_2.to_csv(os.path.join(resultpath, 'modelcomparisons_2.csv'))\n",
    "\n",
    "modelcomparisons_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
